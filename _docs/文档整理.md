项目整理





# MySQL和ES同步一致性如何保证的？

现在的方案是，写mysql表任务在DAG中作为写es输入的前置任务。前端筛选条件众多，字段来自不同的表，例如basic基本信息表、sale销售信息表、trade交易信息表等，分别对应DAG中不同数据任务，通过同步双写保持一致性不太好实现，且必要性不是很高，而且平台对实时性要求没有那么高，短暂不一致业务可以接受，保证最终一致性即可。

## 4 种 MySQL 同步 ES 方案，yyds！

[程序员鱼皮](javascript:void(0);)

*2023年10月01日 23:29* *江苏*

以下文章来源于楼仔 ，作者楼仔

数据同步是一个很常见的业务场景。本文会讲述数据同步的 4 种方案，并给出常用数据迁移工具，干货满满！

先上文章目录：

![图片](https://mmbiz.qpic.cn/mmbiz_png/sXFqMxQoVLGE9pUJBa9xFGjGQ7CM5oY3JFu6HD1NicBZysibiblEU1gjoG0AUMPPkdc5KfHzbewyDAHn0035buorg/640?wx_fmt=png&wxfrom=13&tp=wxpic)

## 1. 前言

在实际项目开发中，我们经常将 MySQL 作为业务数据库，ES 作为查询数据库，用来实现读写分离，缓解 MySQL 数据库的查询压力，应对海量数据的复杂查询。

这其中有一个很重要的问题，就是如何实现 MySQL 数据库和 ES 的数据同步，今天和大家聊聊 MySQL 和 ES 数据同步的各种方案。

我们先看看下面 4 种常用的数据同步方案。

## 2. 数据同步方案

### 2.1 同步双写

这是一种最为简单的方式，在将数据写到 MySQL 时，同时将数据写到 ES。

![图片](https://mmbiz.qpic.cn/mmbiz_png/sXFqMxQoVLGE9pUJBa9xFGjGQ7CM5oY3lpN63pqkRPYdONoWb7IhichRuLAvaQsyDnJIhZ2CQFgmBLnebAWpNFg/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

优点：

- 业务逻辑简单；
- 实时性高。

缺点：

- 硬编码，有需要写入 MySQL 的地方都需要添加写入 ES 的代码；
- 业务强耦合；
- 存在双写失败丢数据风险；
- 性能较差，本来 MySQL 的性能不是很高，再加一个 ES，系统的性能必然会下降。

### 2.2 异步双写

针对多数据源写入的场景，可以借助 MQ 实现异步的多源写入。

![图片](https://mmbiz.qpic.cn/mmbiz_png/sXFqMxQoVLGE9pUJBa9xFGjGQ7CM5oY3vaia3CvJJN4sQdZT0QO1ukJ7pmNkLvx9Dg2bKahc4eLqtqW16SUA9Eg/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

优点：

- 性能高；
- 不易出现数据丢失问题，主要基于 MQ 消息的消费保障机制，比如 ES 宕机或者写入失败，还能重新消费 MQ 消息；
- 多源写入之间相互隔离，便于扩展更多的数据源写入。

缺点：

- 硬编码问题，接入新的数据源需要实现新的消费者代码；
- 系统复杂度增加，引入了消息中间件；
- MQ是异步消费模型，用户写入的数据不一定可以马上看到，造成延时。

### 2.3 基于 SQL 抽取

上面两种方案中都存在硬编码问题，代码的侵入性太强，如果对实时性要求不高的情况下，可以考虑用定时器来处理：

1. 数据库的相关表中增加一个字段为 timestamp 的字段，任何 CURD 操作都会导致该字段的时间发生变化；
2. 原来程序中的 CURD 操作不做任何变化；
3. 增加一个定时器程序，让该程序按一定的时间周期扫描指定的表，把该时间段内发生变化的数据提取出来；
4. 逐条写入到 ES 中。

![图片](https://mmbiz.qpic.cn/mmbiz_png/sXFqMxQoVLGE9pUJBa9xFGjGQ7CM5oY3QzuY4Kh6NV4KumRJibP5rSBmRpkPm6QFnOr2zgDuaUwhGwps5jD3dOA/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

优点：

- 不改变原来代码，没有侵入性、没有硬编码；
- 没有业务强耦合，不改变原来程序的性能；
- Worker 代码编写简单不需要考虑增删改查。

缺点：

- 时效性较差，由于是采用定时器根据固定频率查询表来同步数据，尽管将同步周期设置到秒级，也还是会存在一定时间的延迟；
- 对数据库有一定的轮询压力，一种改进方法是将轮询放到压力不大的从库上。

> 经典方案：借助 Logstash 实现数据同步，其底层实现原理就是根据配置定期使用 SQL 查询新增的数据写入 ES 中，实现数据的增量同步。

### 2.4 基于 Binlog 实时同步

上面三种方案要么有代码侵入，要么有硬编码，要么有延迟，那么有没有一种方案既能保证数据同步的实时性又没有代入侵入呢？

当然有，可以利用 MySQL 的 Binlog 来进行同步。

![图片](https://mmbiz.qpic.cn/mmbiz_png/sXFqMxQoVLGE9pUJBa9xFGjGQ7CM5oY3ib3dUbkDticWOF0ibS7TkLHhE7PibmIgaO91O2YcYMuYbda9ibQf18RAzgg/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

具体步骤如下：

- 读取 MySQL 的 Binlog 日志，获取指定表的日志信息；
- 将读取的信息转为 MQ；
- 编写一个 MQ 消费程序；
- 不断消费 MQ，每消费完一条消息，将消息写入到 ES 中。

优点：

- 没有代码侵入、没有硬编码；
- 原有系统不需要任何变化，没有感知；
- 性能高；
- 业务解耦，不需要关注原来系统的业务逻辑。

缺点：

- 构建 Binlog 系统复杂；
- 如果采用 MQ 消费解析的 Binlog 信息，也会像方案二一样存在 MQ 延时的风险。

## 3. 数据迁移工具选型

对于上面 4 种数据同步方案，“基于 Binlog 实时同步”方案是目前最常用的，也诞生了很多优秀的数据迁移工具，这里主要对这些迁移工具进行介绍。

这些数据迁移工具，很多都是**基于 Binlog 订阅的方式实现**，**模拟一个 MySQL Slave 订阅 Binlog 日志，从而实现 CDC**（Change Data Capture），将已提交的更改发送到下游，包括 INSERT、DELETE、UPDATE。

至于如何伪装？大家需要先了解 MySQL 的主从复制原理，需要学习这块知识的同学，可以看我之前写的高并发教程，里面有详细讲解。

### 3.1 Canal

基于数据库增量日志解析，提供增量数据订阅&消费，目前主要支持 MySQL。

Canal 原理就是**伪装成 MySQL 的从节点，从而订阅 master 节点的 Binlog 日志**，主要流程为：

1. Canal 服务端向 MySQL 的 master 节点传输 dump 协议；
2. MySQL 的 master 节点接收到 dump 请求后推送 Binlog 日志给 Canal 服务端，解析 Binlog 对象（原始为 byte 流）转成 Json 格式；
3. Canal 客户端通过 TCP 协议或 MQ 形式监听 Canal 服务端，同步数据到 ES。

![图片](https://mmbiz.qpic.cn/mmbiz_png/sXFqMxQoVLGE9pUJBa9xFGjGQ7CM5oY3CI5Yl440E6pibpic33TB8TWBSoHICkfX4UkLMiaTtia59ic3YbFkF74wfuw/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

下面是 Canal 执行的核心流程，其中 Binlog Parser 主要负责 Binlog 的提取、解析和推送，EventSink 负责数据的过滤 、路由和加工，仅作了解即可。

![图片](https://mmbiz.qpic.cn/mmbiz_png/sXFqMxQoVLGE9pUJBa9xFGjGQ7CM5oY3zcyzPAalTIYamIxzoNKY3wN3CQBHMRV7LYCpUaU7T0J2aPNq18piacg/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

### 3.2 阿里云 DTS

数据传输服务 DTS（Data Transmission Service）支持 RDBMS、NoSQL、OLAP 等多种数据源之间的数据传输。

它提供了数据迁移、实时数据订阅及数据实时同步等多种数据传输方式。相对于第三方数据流工具，DTS 提供丰富多样、高性能、高安全可靠的传输链路，同时它提供了诸多便利功能，极大方便了传输链路的创建及管理。

特点：

- 多数据源：支持 RDBMS、NoSQL、OLAP 等多种数据源间的数据传输；
- 多传输方式：支持多种传输方式，包括数据迁移、实时数据订阅及数据实时同步；
- 高性能：底层采用了多种性能优化措施，全量数据迁移高峰期时性能可以达到70MB/s，20万的TPS，使用高规格服务器来保证每条迁移或同步链路都能拥有良好的传输性能；
- 高可用：底层为服务集群，如果集群内任何一个节点宕机或发生故障，控制中心都能够将这个节点上的所有任务快速切换到其他节点上，链路稳定性高；
- 简单易用：提供可视化管理界面，提供向导式的链路创建流程，用户可以在其控制台简单轻松地创建传输链路；
- 需要付费。

再看看 DTS 的系统架构。

![图片](https://mmbiz.qpic.cn/mmbiz_png/sXFqMxQoVLGE9pUJBa9xFGjGQ7CM5oY3COmqBzfM08y28V4tMTOyMI0G3WVfRARcAlCfFWc3CNCTuXibltDPZSw/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

- 高可用：数据传输服务内部每个模块都有主备架构，保证系统高可用。容灾系统实时检测每个节点的健康状况，一旦发现某个节点异常，会将链路快速切换到其他节点。
- 数据源地址动态适配：对于数据订阅及同步链路，容灾系统还会监测数据源的连接地址切换等变更操作，一旦发现数据源发生连接地址变更，它会动态适配数据源新的连接方式，在数据源变更的情况下，保证链路的稳定性。

更多内容，请查看阿里官方文档：https://help.aliyun.com/product/26590.html

### 3.3 Databus

Databus 是一个低延迟、可靠的、支持事务的、保持一致性的数据变更抓取系统。由 LinkedIn 于 2013 年开源。

Databus 通过挖掘数据库日志的方式，将数据库变更实时、可靠的从数据库拉取出来，业务可以通过定制化 client 实时获取变更并进行其他业务逻辑。

特点：

- 多数据源：Databus 支持多种数据来源的变更抓取，包括 Oracle 和 MySQL。
- 可扩展、高度可用：Databus 能扩展到支持数千消费者和事务数据来源，同时保持高度可用性。
- 事务按序提交：Databus 能保持来源数据库中的事务完整性，并按照事务分组和来源的提交顺寻交付变更事件。
- 低延迟、支持多种订阅机制：数据源变更完成后，Databus 能在毫秒级内将事务提交给消费者。同时，消费者使用D atabus 中的服务器端过滤功能，可以只获取自己需要的特定数据。
- 无限回溯：对消费者支持无限回溯能力，例如当消费者需要产生数据的完整拷贝时，它不会对数据库产生任何额外负担。当消费者的数据大大落后于来源数据库时，也可以使用该功能。

再看看 Databus 的系统架构。

Databus 由 Relays、bootstrap 服务和 Client lib 等组成，Bootstrap 服务中包括 Bootstrap Producer 和 Bootstrap Server。

![图片](https://mmbiz.qpic.cn/mmbiz_png/sXFqMxQoVLGE9pUJBa9xFGjGQ7CM5oY3bMUe41x7njibia51Xeeic8fJTT4S3HiaVCic3HL3ESWVtRLO3a9kl5fM6lQ/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

- 快速变化的消费者直接从 Relay 中取事件；
- 如果一个消费者的数据更新大幅落后，它要的数据就不在 Relay 的日志中，而是需要**请求 Bootstrap 服务，返回的将会是自消费者上次处理变更之后的所有数据变更快照。**

开源地址：https://github.com/linkedin/databus

## 总结

本文主要对Mysql和ES进行数据同步的常见方案进行了汇总说明。

- `同步双写`是最简单的同步方式，能最大程度保证数据同步写入的实时性，最大的问题是代码侵入性太强。
- `异步双写`引入了消息中间件，由于MQ都是异步消费模型，所以可能出现数据同步延迟的问题。好处是在大规模消息同步时吞吐量更、高性能更好，便于接入更多的数据源，且各个数据源数据消费写入相互隔离互不影响。
- `基于Mysql表定时扫描同步` ，原理是通过定时器定时扫描表中的增量数据进行数据同步，不会产生代码侵入，但由于是定时扫描同步，所以也会存在数据同步延迟问题，典型实现是采用 Logstash 实现增量同步。
- `基于Binlog实时同步` ，原理是通过监听Mysql的binlog日志进行增量同步数据。不会产生代码侵入，数据同步的实时也能得到保障，弊端是Binlog系统都较为复杂。典型实现是采用 canal 实现数据同步。



# 数据库和缓存如何保证一致性？



## 数据库和缓存如何保证一致性？



### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#先更新数据库-还是先更新缓存) 先更新数据库，还是先更新缓存？

![图片](https://cdn.xiaolincoding.com//mysql/other/b3bc9c4851ed731a36c9fee0f64264fe.png)

**由于引入了缓存，那么在数据更新时，不仅要更新数据库，而且要更新缓存，这两个更新操作存在前后的问题**：

- 先更新数据库，再更新缓存；
- 先更新缓存，再更新数据库；

#### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#先更新数据库-再更新缓存) 先更新数据库，再更新缓存

举个例子，比如「请求 A 」和「请求 B 」两个请求，同时更新「同一条」数据，则可能出现这样的顺序：

![图片](https://cdn.xiaolincoding.com//mysql/other/8febac10b14bed16cb96d1d944cd08da.png)

A 请求先将数据库的数据更新为 1，然后在更新缓存前，请求 B 将数据库的数据更新为 2，紧接着也把缓存更新为 2，然后 A 请求更新缓存为 1。

此时，数据库中的数据是 2，而缓存中的数据却是 1，**出现了缓存和数据库中的数据不一致的现象**。

#### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#先更新缓存-再更新数据库) 先更新缓存，再更新数据库

那换成「**先更新缓存，再更新数据库**」这个方案，还会有问题吗？

依然还是存在并发的问题，分析思路也是一样。

假设「请求 A 」和「请求 B 」两个请求，同时更新「同一条」数据，则可能出现这样的顺序：

![图片](https://cdn.xiaolincoding.com//mysql/other/454a8228a6549176ad7e0484fba3c92b.png)

A 请求先将缓存的数据更新为 1，然后在更新数据库前，B 请求来了， 将缓存的数据更新为 2，紧接着把数据库更新为 2，然后 A 请求将数据库的数据更新为 1。

此时，数据库中的数据是 1，而缓存中的数据却是 2，**出现了缓存和数据库中的数据不一致的现象**。

所以，**无论是「先更新数据库，再更新缓存」，还是「先更新缓存，再更新数据库」，这两个方案都存在并发问题，当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象**。

### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#先更新数据库-还是先删除缓存) 先更新数据库，还是先删除缓存？

阿旺定位出问题后，思考了一番后，决定在更新数据时，**不更新缓存，而是删除缓存中的数据。然后，到读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。**

阿旺想的这个策略是有名字的，是叫 **Cache Aside 策略**，中文是叫**旁路缓存策略**。

该策略又可以细分为「读策略」和「写策略」。

![图片](https://cdn.xiaolincoding.com//mysql/other/6e3db3ba2f829ddc14237f5c7c00e7ce.png)

**写策略的步骤：**

- 更新数据库中的数据；
- 删除缓存中的数据。

**读策略的步骤：**

- 如果读取的数据命中了缓存，则直接返回数据；
- 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。

阿旺在想到「写策略」的时候，又陷入更深层次的思考，到底该选择哪种顺序呢？

- 先删除缓存，再更新数据库；
- 先更新数据库，再删除缓存。

阿旺这次经过上次教训，不再「想当然」的乱选方案，因为老板这次给的饼很大啊，必须把握住。

于是阿旺用并发的角度来分析，看看这两种方案哪个可以保证数据库与缓存的数据一致性。

#### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#先删除缓存-再更新数据库) 先删除缓存，再更新数据库

阿旺还是以用户表的场景来分析。

假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B  要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。

![图片](https://cdn.xiaolincoding.com//mysql/other/cc208c2931b4e889d1a58cb655537767.png)

最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致。

可以看到，**先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题**。

#### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#先更新数据库-再删除缓存) 先更新数据库，再删除缓存

继续用「读 + 写」请求的并发的场景来分析。

假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中。

![图片](https://cdn.xiaolincoding.com//mysql/other/1cc7401143e79383ead96582ac11b615.png)

最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库数据不一致。

从上面的理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，**但是在实际中，这个问题出现的概率并不高**。

**因为缓存的写入通常要远远快于数据库的写入**，所以在**实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况**。

而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。

所以，**「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的**。

而且阿旺为了确保万无一失，还给缓存数据加上了「**过期时间**」，就算在这期间存在缓存数据不一致，有过期时间来兜底，这样也能达到最终一致。

阿旺思考到这一步后，觉得自己真的是个小天才，因为他竟然想到了个「天衣无缝」的方案，他二话不说就采用了这个方案，又经过几天的折腾，终于完成了。

他自信满满的向老板汇报，已经解决了上次客户的投诉的问题了。老板觉得阿旺这小伙子不错，这么快就解决问题了，然后让阿旺在观察几天。

事情哪有这么顺利呢？结果又没过多久，老板又收到客户的投诉了，**说自己明明更新了数据，但是数据要过一段时间才生效**，客户接受不了。

老板面无表情的找上阿旺，让阿旺尽快查出问题。

阿旺得知又有 Bug 就更慌了，立马就登录服务器去排查问题，查看日志后得知了原因。

「先更新数据库， 再删除缓存」其实是两个操作，前面的所有分析都是建立在这两个操作都能同时执行成功，而这次客户投诉的问题就在于，**在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值**。

好在之前给缓存加上了过期时间，所以才会出现客户说的过一段时间才更新生效的现象，假设如果没有这个过期时间的兜底，那后续的请求读到的就会一直是缓存中的旧数据，这样问题就更大了。

所以新的问题来了，**如何保证「先更新数据库 ，再删除缓存」这两个操作能执行成功？**

阿旺分析出问题后，慌慌张张的向老板汇报了问题。

老板知道事情后，又给了阿旺几天来解决这个问题，画饼的事情这次没有再提了。

**阿旺会用什么方式来解决这个问题呢？**

**老板画的饼事情，能否兑现给阿旺呢？**

预知后事，且听下回阿旺的故事。

### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#小结) 小结

阿旺的事情就聊到这，我们继续说点其他。

「先更新数据库，再删除缓存」的方案虽然保证了数据库与缓存的数据一致性，但是每次更新数据的时候，缓存的数据都会被删除，这样会对缓存的命中率带来影响。

所以，**如果我们的业务对缓存命中率有很高的要求，我们可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况**。

但是这个方案前面我们也分析过，在两个更新请求并发执行的时候，会出现数据不一致的问题，因为更新数据库和更新缓存这两个操作是独立的，而我们又没有对操作做任何并发控制，那么当两个线程并发更新它们的话，就会因为写入顺序的不同造成数据的不一致。

所以我们得增加一些手段来解决这个问题，这里提供两种做法：

- 在更新缓存前先加个**分布式锁**，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。
- 在更新完缓存时，给缓存加上较短的**过期时间**，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。

对了，**针对「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致**的解决办法是「**延迟双删**」。

延迟双删实现的伪代码如下：

```lua
#删除缓存
redis.delKey(X)
#更新数据库
db.update(X)
#睡眠
Thread.sleep(N)
#再删除缓存
redis.delKey(X)
```

加了个睡眠时间，主要是为了**确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完，再删除缓存**。

所以，**请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间**。

但是具体睡眠多久其实是个**玄学**，很难评估出来，所以这个方案也只是**尽可能**保证一致性而已，极端情况下，依然也会出现缓存不一致的现象。

因此，还是比较建议用「先更新数据库，再删除缓存」的方案。

------

### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#前情回顾) 前情回顾

上回程序员阿旺为了提升数据访问的性能，引入 Redis 作为 MySQL 缓存层，但是这件事情并不是那么简单，因为还要考虑 Redis 和 MySQL 双写一致性的问题。

阿旺经过一番周折，最终选用了「**先更新数据库，再删缓存**」的策略，原因是这个策略即使在并发读写时，也能最大程度保证数据一致性。

聪明的阿旺还搞了个**兜底的方案**，就是**给缓存加上了过期时间**。

本以为就这样不会在出现数据一致性的问题，结果将功能上线后，老板还是收到用户的投诉「说自己明明更新了数据，但是数据要过一段时间才生效」，客户接受不了。

老板转告给了阿旺，阿旺得知又有 Bug 就更慌了，立马就登录服务器去排查问题，查看日志后得知了原因。

「先更新数据库， 再删除缓存」其实是两个操作，这次客户投诉的问题就在于，**在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值，而数据库是最新值**。

好在之前给缓存加上了过期时间，所以才会出现客户说的过一段时间才更新生效的现象，假设如果没有这个**过期时间的兜底**，那后续的请求读到的就会一直是缓存中的旧数据，这样问题就更大了。

所以新的问题来了，**如何保证「先更新数据库 ，再删除缓存」这两个操作能执行成功？**

阿旺分析出问题后，慌慌张张的向老板汇报了问题。

老板知道事情后，又给了阿旺几天来解决这个问题，画饼的事情这次没有再提了。

- 阿旺会用什么方式来解决这个问题呢？
- 老板画的饼事情，能否兑现给阿旺呢？

### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#如何保证两个操作都能执行成功) 如何保证两个操作都能执行成功？

这次用户的投诉是因为在删除缓存（第二个操作）的时候失败了，导致缓存还是旧值，而数据库是最新值，造成数据库和缓存数据不一致的问题，会对敏感业务造成影响。

举个例子，来说明下。

应用要把数据 X 的值从 1 更新为 2，先成功更新了数据库，然后在 Redis 缓存中删除 X 的缓存，但是这个操作却失败了，这个时候数据库中 X 的新值为 2，Redis 中的 X 的缓存值为 1，出现了数据库和缓存数据不一致的问题。

![图片](https://cdn.xiaolincoding.com//mysql/other/2a2ea2854bbc3ae8ae86d7da45fa32ee.png)

那么，后续有访问数据 X 的请求，会先在 Redis 中查询，因为缓存并没有 诶删除，所以会缓存命中，但是读到的却是旧值 1。

其实不管是先操作数据库，还是先操作缓存，只要第二个操作失败都会出现数据一致的问题。

问题原因知道了，该怎么解决呢？有两种方法：

- 重试机制。
- 订阅 MySQL binlog，再操作缓存。

先来说第一种。

##### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#重试机制) 重试机制

我们可以引入**消息队列**，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。

- 如果应用**删除缓存失败**，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是**重试机制**。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。
- 如果**删除缓存成功**，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。

举个例子，来说明重试机制的过程。

![图片](https://cdn.xiaolincoding.com//mysql/other/a4440f0d572612e0832b903e4a62bd2b.png)

##### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#订阅-mysql-binlog-再操作缓存) 订阅 MySQL binlog，再操作缓存

「**先更新数据库，再删缓存**」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。

于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。

**Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL  收到请求后，就会开始推送 Binlog 给 Canal**，Canal 解析 Binlog  字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。

下图是 Canal 的工作原理：

![图片](https://cdn.xiaolincoding.com//mysql/other/2ee2280e9f59b6b4879ebdec6eb0cf52.png)

所以，**如果要想保证「先更新数据库，再删缓存」策略第二个操作能执行成功，我们可以使用「消息队列来重试缓存的删除」，或者「订阅 MySQL binlog 再操作缓存」，这两种方法有一个共同的特点，都是采用异步操作缓存。**

### [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#老板发饼啦) 老板发饼啦

阿旺由于对消息队列比较熟悉，所以他决定采用「**消息队列来重试缓存的删除**」的方案，来解决这次的用户问题。

## [#](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#读者提问) 读者提问

> 为什么是删除缓存，而不是更新缓存呢？

删除一个数据，相比更新一个数据更加轻量级，出问题的概率更小。在实际业务中，缓存的数据可能不是直接来自数据库表，也许来自多张底层数据表的聚合。

比如商品详情信息，在底层可能会关联商品表、价格表、库存表等，如果更新了一个价格字段，那么就要更新整个数据库，还要关联的去查询和汇总各个周边业务系统的数据，这个操作会非常耗时。  从另外一个角度，不是所有的缓存数据都是频繁访问的，更新后的缓存可能会长时间不被访问，所以说，从计算资源和整体性能的考虑，更新的时候删除缓存，等到下次查询命中再填充缓存，是一个更好的方案。

系统设计中有一个思想叫 Lazy Loading，适用于那些加载代价大的操作，删除缓存而不是更新缓存，就是懒加载思想的一个应用。



-----------

# 缓存和数据库一致性问题，看这篇就够了

原创 Magic Kaito

[水滴与银弹](javascript:void(0);)

*2021年09月08日 08:40*

> 阅读本文大约需要 10 分钟。

你好，我是 Kaito。

如何保证缓存和数据库一致性，这是一个老生常谈的话题了。

但很多人对这个问题，依旧有很多疑惑：

- 到底是更新缓存还是删缓存？
- 到底选择先更新数据库，再删除缓存，还是先删除缓存，再更新数据库？
- 为什么要引入消息队列保证一致性？
- 延迟双删会有什么问题？到底要不要用？
- ...

这篇文章，我们就来把这些问题讲清楚。

**这篇文章干货很多，希望你可以耐心读完。**

![图片](https://mmbiz.qpic.cn/mmbiz_png/gB9Yvac5K3OezNCibL5S9oyeYqJBQVZCo41CpvfXVh4yAMdkW8giaHjxcLWWicuEn5zejdZoLsr9LjXH5yGsSjSxQ/640?wx_fmt=png&wxfrom=13&tp=wxpic)

# 引入缓存提高性能

我们从最简单的场景开始讲起。

如果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可，这时你的架构模型是这样的：

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OezNCibL5S9oyeYqJBQVZCo1NdGKV0ptDl4ZsCXKfwXLl1Kp35aOG1Iku9K2EJ8Y7v5bM91jK5NLQ/640?wx_fmt=jpeg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

但随着业务量的增长，你的项目请求量越来越大，这时如果每次都从数据库中读数据，那肯定会有性能问题。

这个阶段通常的做法是，引入「缓存」来提高读性能，架构模型就变成了这样：

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OezNCibL5S9oyeYqJBQVZCo3lYxFg1icDgHngialHe8ibUDKCvfib4DmTMo36wJv0FeZ5ex0kId1LTOpw/640?wx_fmt=jpeg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

当下优秀的缓存中间件，当属 Redis 莫属，它不仅性能非常高，还提供了很多友好的数据类型，可以很好地满足我们的业务需求。

但引入缓存之后，你就会面临一个问题：**之前数据只存在数据库中，现在要放到缓存中读取，具体要怎么存呢？**

最简单直接的方案是「全量数据刷到缓存中」：

- 数据库的数据，全量刷入缓存（不设置失效时间）
- 写请求只更新数据库，不更新缓存
- 启动一个定时任务，定时把数据库的数据，更新到缓存中

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OezNCibL5S9oyeYqJBQVZCo0jeBz8G4Kwr7ZgicicEQARCTuaFibHOf1pKzVnicVbiaxzGtKukzrEqGOOA/640?wx_fmt=jpeg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

这个方案的优点是，所有读请求都可以直接「命中」缓存，不需要再查数据库，性能非常高。

但缺点也很明显，有 2 个问题：

1. **缓存利用率低**：不经常访问的数据，还一直留在缓存中
2. **数据不一致**：因为是「定时」刷新缓存，缓存和数据库存在不一致（取决于定时任务的执行频率）

所以，这种方案一般更适合业务「体量小」，且对数据一致性要求不高的业务场景。

那如果我们的业务体量很大，怎么解决这 2 个问题呢？

# 缓存利用率和一致性问题

先来看第一个问题，如何提高缓存利用率？

想要缓存利用率「最大化」，我们很容易想到的方案是，缓存中只保留最近访问的「热数据」。但具体要怎么做呢？

我们可以这样优化：

- 写请求依旧只写数据库
- 读请求先读缓存，如果缓存不存在，则从数据库读取，并重建缓存
- 同时，写入缓存中的数据，都设置失效时间

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OezNCibL5S9oyeYqJBQVZCo8ic8WbuqDQcJ2bVyia7t9rOu9CGyJnCkWQs16WNibAwdV0GbH3q0K6ZMw/640?wx_fmt=jpeg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

这样一来，缓存中不经常访问的数据，随着时间的推移，都会逐渐「过期」淘汰掉，最终缓存中保留的，都是经常被访问的「热数据」，缓存利用率得以最大化。

再来看数据一致性问题。

要想保证缓存和数据库「实时」一致，那就不能再用定时任务刷新缓存了。

所以，当数据发生更新时，我们不仅要操作数据库，还要一并操作缓存。具体操作就是，修改一条数据时，不仅要更新数据库，也要连带缓存一起更新。

但数据库和缓存都更新，又存在先后问题，那对应的方案就有 2 个：

1. 先更新缓存，后更新数据库
2. 先更新数据库，后更新缓存

哪个方案更好呢？

先不考虑并发问题，正常情况下，无论谁先谁后，都可以让两者保持一致，但现在我们需要重点考虑「异常」情况。

因为操作分为两步，那么就很有可能存在「第一步成功、第二步失败」的情况发生。

这 2 种方案我们一个个来分析。

**1) 先更新缓存，后更新数据库**

如果缓存更新成功了，但数据库更新失败，那么此时缓存中是最新值，但数据库中是「旧值」。

虽然此时读请求可以命中缓存，拿到正确的值，但是，一旦缓存「失效」，就会从数据库中读取到「旧值」，重建缓存也是这个旧值。

这时用户会发现自己之前修改的数据又「变回去」了，对业务造成影响。

**2) 先更新数据库，后更新缓存**

如果数据库更新成功了，但缓存更新失败，那么此时数据库中是最新值，缓存中是「旧值」。

之后的读请求读到的都是旧数据，只有当缓存「失效」后，才能从数据库中得到正确的值。

这时用户会发现，自己刚刚修改了数据，但却看不到变更，一段时间过后，数据才变更过来，对业务也会有影响。

可见，无论谁先谁后，但凡后者发生异常，就会对业务造成影响。那怎么解决这个问题呢？

别急，后面我会详细给出对应的解决方案。

我们继续分析，除了操作失败问题，还有什么场景会影响数据一致性？

这里我们还需要重点关注：**并发问题**。

# 并发引发的一致性问题

假设我们采用「先更新数据库，再更新缓存」的方案，并且两步都可以「成功执行」的前提下，如果存在并发，情况会是怎样的呢？

有线程 A 和线程 B 两个线程，需要更新「同一条」数据，会发生这样的场景：

1. 线程 A 更新数据库（X = 1）
2. 线程 B 更新数据库（X = 2）
3. 线程 B 更新缓存（X = 2）
4. 线程 A 更新缓存（X = 1）

最终 X 的值在缓存中是 1，在数据库中是 2，发生不一致。

也就是说，A 虽然先于 B 发生，但 B 操作数据库和缓存的时间，却要比 A 的时间短，执行时序发生「错乱」，最终这条数据结果是不符合预期的。

> 同样地，采用「先更新缓存，再更新数据库」的方案，也会有类似问题，这里不再详述。

除此之外，我们从「缓存利用率」的角度来评估这个方案，也是不太推荐的。

这是因为每次数据发生变更，都「无脑」更新缓存，但是缓存中的数据不一定会被「马上读取」，这就会导致缓存中可能存放了很多不常访问的数据，浪费缓存资源。

而且很多情况下，写到缓存中的值，并不是与数据库中的值一一对应的，很有可能是先查询数据库，再经过一系列「计算」得出一个值，才把这个值才写到缓存中。

由此可见，这种「更新数据库 + 更新缓存」的方案，不仅缓存利用率不高，还会造成机器性能的浪费。

所以此时我们需要考虑另外一种方案：**删除缓存**。

# 删除缓存可以保证一致性吗？

删除缓存对应的方案也有 2 种：

1. 先删除缓存，后更新数据库
2. 先更新数据库，后删除缓存

经过前面的分析我们已经得知，但凡「第二步」操作失败，都会导致数据不一致。

这里我不再详述具体场景，你可以按照前面的思路推演一下，就可以看到依旧存在数据不一致的情况。

这里我们重点来看「并发」问题。

**1) 先删除缓存，后更新数据库**

如果有 2 个线程要并发「读写」数据，可能会发生以下场景：

1. 线程 A 要更新 X = 2（原值 X = 1）
2. 线程 A 先删除缓存
3. 线程 B 读缓存，发现不存在，从数据库中读取到旧值（X = 1）
4. 线程 A 将新值写入数据库（X = 2）
5. 线程 B 将旧值写入缓存（X = 1）

最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。

可见，先删除缓存，后更新数据库，当发生「读+写」并发时，还是存在数据不一致的情况。

**2) 先更新数据库，后删除缓存**

依旧是 2 个线程并发「读写」数据：

1. 缓存中 X 不存在（数据库 X = 1）
2. 线程 A 读取数据库，得到旧值（X = 1）
3. 线程 B 更新数据库（X = 2)
4. 线程 B 删除缓存
5. 线程 A 将旧值写入缓存（X = 1）

最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），也发生不一致。

这种情况「理论」来说是可能发生的，但实际真的有可能发生吗？

其实概率「很低」，这是因为它必须满足 3 个条件：

1. **缓存刚好已失效**
2. **读请求 + 写请求并发**
3. **更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5）**

仔细想一下，**条件 3 发生的概率其实是非常低的**。

**因为写数据库一般会先「加锁」，所以写数据库，通常是要比读数据库的时间更长的**。

这么来看，「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的。

所以，我们应该采用这种方案，来操作数据库和缓存。

好，解决了并发问题，我们继续来看前面遗留的，**第二步执行「失败」导致数据不一致的问题**。

# 如何保证两步都执行成功？

前面我们分析到，无论是更新缓存还是删除缓存，只要第二步发生失败，那么就会导致数据库和缓存不一致。

**保证第二步成功执行，就是解决问题的关键。**

想一下，程序在执行过程中发生异常，最简单的解决办法是什么？

答案是：**重试**。

是的，其实这里我们也可以这样做。

无论是先操作缓存，还是先操作数据库，但凡后者执行失败了，我们就可以发起重试，尽可能地去做「补偿」。

那这是不是意味着，只要执行失败，我们「无脑重试」就可以了呢？

答案是否定的。现实情况往往没有想的这么简单，失败后立即重试的问题在于：

- 立即重试很大概率「还会失败」
- 「重试次数」设置多少才合理？
- 重试会一直「占用」这个线程资源，无法服务其它客户端请求

看到了么，虽然我们想通过重试的方式解决问题，但这种「同步」重试的方案依旧不严谨。

那更好的方案应该怎么做？

答案是：**异步重试**。什么是异步重试？

其实就是把重试请求写到「消息队列」中，然后由专门的消费者来重试，直到成功。

或者更直接的做法，为了避免第二步执行失败，我们可以把操作缓存这一步，直接放到消息队列中，由消费者来操作缓存。

到这里你可能会问，写消息队列也有可能会失败啊？而且，引入消息队列，这又增加了更多的维护成本，这样做值得吗？

这个问题很好，但我们思考这样一个问题：如果在执行失败的线程中一直重试，还没等执行成功，此时如果项目「重启」了，那这次重试请求也就「丢失」了，那这条数据就一直不一致了。

所以，这里我们必须把重试或第二步操作放到另一个「服务」中，这个服务用「消息队列」最为合适。这是因为消息队列的特性，正好符合我们的需求：

- **消息队列保证可靠性**：写到队列中的消息，成功消费之前不会丢失（重启项目也不担心）
- **消息队列保证消息成功投递**：下游从队列拉取消息，成功消费后才会删除消息，否则还会继续投递消息给消费者（符合我们重试的场景）

至于写队列失败和消息队列的维护成本问题：

- **写队列失败**：操作缓存和写消息队列，「同时失败」的概率其实是很小的
- **维护成本**：我们项目中一般都会用到消息队列，维护成本并没有新增很多

所以，引入消息队列来解决这个问题，是比较合适的。这时架构模型就变成了这样：

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OezNCibL5S9oyeYqJBQVZCoNNyZnraolIYC8NntRZu8R0VpQp0iaXsohT5gjf4QpV0biah4iaRiaHOcyw/640?wx_fmt=jpeg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

那如果你确实不想在应用中去写消息队列，是否有更简单的方案，同时又可以保证一致性呢？

方案还是有的，这就是近几年比较流行的解决方案：**订阅数据库变更日志，再操作缓存**。

具体来讲就是，我们的业务应用在修改数据时，「只需」修改数据库，无需操作缓存。

那什么时候操作缓存呢？这就和数据库的「变更日志」有关了。

拿 MySQL 举例，当一条数据发生修改时，MySQL 就会产生一条变更日志（Binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OezNCibL5S9oyeYqJBQVZCowjAarwD2g3lIfCPsvhEHGaohPHVa47GR9d1GUgj0Eta1ketClKZjfw/640?wx_fmt=jpeg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

订阅变更日志，目前也有了比较成熟的开源中间件，例如阿里的 canal，使用这种方案的优点在于：

- **无需考虑写消息队列失败情况**：只要写 MySQL 成功，Binlog 肯定会有
- **自动投递到下游队列**：canal 自动把数据库变更日志「投递」给下游的消息队列

当然，与此同时，我们需要投入精力去维护 canal 的高可用和稳定性。

> 如果你有留意观察很多数据库的特性，就会发现其实很多数据库都逐渐开始提供「订阅变更日志」的功能了，相信不远的将来，我们就不用通过中间件来拉取日志，自己写程序就可以订阅变更日志了，这样可以进一步简化流程。

至此，我们可以得出结论，想要保证数据库和缓存一致性，**推荐采用「先更新数据库，再删除缓存」方案，并配合「消息队列」或「订阅变更日志」的方式来做**。

# 主从库延迟和延迟双删问题

到这里，还有 2 个问题，是我们没有重点分析过的。

**第一个问题**，还记得前面讲到的「先删除缓存，再更新数据库」方案，导致不一致的场景么？

这里我再把例子拿过来让你复习一下：

2 个线程要并发「读写」数据，可能会发生以下场景：

1. 线程 A 要更新 X = 2（原值 X = 1）
2. 线程 A 先删除缓存
3. 线程 B 读缓存，发现不存在，从数据库中读取到旧值（X = 1）
4. 线程 A 将新值写入数据库（X = 2）
5. 线程 B 将旧值写入缓存（X = 1）

最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。

**第二个问题**：是关于「读写分离 + 主从复制延迟」情况下，缓存和数据库一致性的问题。

在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」其实也会导致不一致：

1. 线程 A 更新主库 X = 2（原值 X = 1）
2. 线程 A 删除缓存
3. 线程 B 查询缓存，没有命中，查询「从库」得到旧值（从库 X = 1）
4. 从库「同步」完成（主从库 X = 2）
5. 线程 B 将「旧值」写入缓存（X = 1）

最终 X 的值在缓存中是 1（旧值），在主从库中是 2（新值），也发生不一致。

看到了么？这 2 个问题的核心在于：**缓存都被回种了「旧值」**。

那怎么解决这类问题呢？

最有效的办法就是，**把缓存删掉**。

但是，不能立即删，而是需要「延迟删」，这就是业界给出的方案：**缓存延迟双删策略**。

按照延时双删策略，这 2 个问题的解决方案是这样的：

**解决第一个问题**：在线程 A 删除缓存、更新完数据库之后，先「休眠一会」，再「删除」一次缓存。

**解决第二个问题**：线程 A 可以生成一条「延时消息」，写到消息队列中，消费者延时「删除」缓存。

这两个方案的目的，都是为了把缓存清掉，这样一来，下次就可以从数据库读取到最新值，写入缓存。

但问题来了，这个「延迟删除」缓存，延迟时间到底设置要多久呢？

- 问题1：延迟时间要大于「主从复制」的延迟时间
- 问题2：延迟时间要大于线程 B 读取数据库 + 写入缓存的时间

但是，**这个时间在分布式和高并发场景下，其实是很难评估的****。**

很多时候，我们都是凭借经验大致估算这个延迟时间，例如延迟 1-5s，只能尽可能地降低不一致的概率。

所以你看，采用这种方案，也只是尽可能保证一致性而已，极端情况下，还是有可能发生不一致。

所以实际使用中，我还是建议你采用「先更新数据库，再删除缓存」的方案，同时，要尽可能地保证「主从复制」不要有太大延迟，降低出问题的概率。

# 可以做到强一致吗？

看到这里你可能会想，这些方案还是不够完美，我就想让缓存和数据库「强一致」，到底能不能做到呢？

其实很难。

要想做到强一致，最常见的方案是 2PC、3PC、Paxos、Raft 这类一致性协议，但它们的性能往往比较差，而且这些方案也比较复杂，还要考虑各种容错问题。

相反，这时我们换个角度思考一下，我们引入缓存的目的是什么？

没错，**性能**。

一旦我们决定使用缓存，那必然要面临一致性问题。性能和一致性就像天平的两端，无法做到都满足要求。

而且，就拿我们前面讲到的方案来说，当操作数据库和缓存完成之前，只要有其它请求可以进来，都有可能查到「中间状态」的数据。

所以如果非要追求强一致，那必须要求所有更新操作完成之前期间，不能有「任何请求」进来。

虽然我们可以通过加「分布锁」的方式来实现，但我们要付出的代价，很可能会超过引入缓存带来的性能提升。

所以，既然决定使用缓存，就必须容忍「一致性」问题，我们只能尽可能地去降低问题出现的概率。

同时我们也要知道，缓存都是有「失效时间」的，就算在这期间存在短期不一致，我们依旧有失效时间来兜底，这样也能达到最终一致。

# 总结

好了，总结一下这篇文章的重点。

1、想要提高应用的性能，可以引入「缓存」来解决

2、引入缓存后，需要考虑缓存和数据库一致性问题，可选的方案有：「更新数据库 + 更新缓存」、「更新数据库 + 删除缓存」

3、更新数据库 + 更新缓存方案，在「并发」场景下无法保证缓存和数据一致性，且存在「缓存资源浪费」和「机器性能浪费」的情况发生

4、在更新数据库 + 删除缓存的方案中，「先删除缓存，再更新数据库」在「并发」场景下依旧有数据不一致问题，解决方案是「延迟双删」，但这个延迟时间很难评估，所以推荐用「先更新数据库，再删除缓存」的方案

5、在「先更新数据库，再删除缓存」方案下，为了保证两步都成功执行，需配合「消息队列」或「订阅变更日志」的方案来做，本质是通过「重试」的方式保证数据一致性

6、在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」也会导致缓存和数据库不一致，缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率

# 后记

本以为这个老生常谈的话题，写起来很好写，没想到在写的过程中，还是挖到了很多之前没有深度思考过的细节。

在这里我也分享 4 点心得给你：

1、性能和一致性不能同时满足，为了性能考虑，通常会采用「最终一致性」的方案

2、掌握缓存和数据库一致性问题，核心问题有 3 点：缓存利用率、并发、缓存 + 数据库一起成功问题

3、失败场景下要保证一致性，常见手段就是「重试」，同步重试会影响吞吐量，所以通常会采用异步重试的方案

4、订阅变更日志的思想，本质是把权威数据源（例如 MySQL）当做 leader 副本，让其它异质系统（例如 Redis / Elasticsearch）成为它的 follower 副本，通过同步变更日志的方式，保证 leader 和 follower 之间保持一致

很多一致性问题，都会采用这些方案来解决，希望我的这些心得对你有所启发。



----------------------

# [缓存里的几种模式（Cache-Aside、Read/Write-Through、Write-back）](https://segmentfault.com/a/1190000040709794)

简单聊下缓存里的几种模式。
**一 Cache-Aside**

1. 读操作：应用先去查询缓存，命中则返回；没命中应用则会去数据库读取数据，写入缓存后返回。

1. 写操作：应用先更新数据库再删除缓存，然后返回。
   可以看到，这种模式下，缓存只有写入与删除而没有修改操作。
   *适用场景*：读多写少。
   *存在的问题*：多线程下易出现数据不一致的问题。

**二 Read/Write-Through**
核心思想：应用需要操作数据时只与缓存组件进行交互；缓存里的数据不会过期。

1. Read-Through，应用查询缓存是否存在，存在则返回；不存在则由缓存组件去数据库加载数据。
2. Write-Through，先查询要写入的数据在缓存是否存在，存在则先更新缓存然后再更新数据库最后返回；如果要写入的数据在缓存不存在，有两对应策略：一种是先将数据写入缓存，然后由缓存组件将数据同步更新到数据库；另一种策略是不写缓存直接将数据写入数据库。
   *适用场景*：读多写少。
   *存在的问题*：
   - 因为应用操作数据时只与缓存组件交互，相对于Cache-Aside而言数据不一致的概率要低一些。
   - 因为此模式下缓存没有过期时间，所以缓存的使用量会非常大。

**三 Write-Back**
Write-Back也称Write-Behind，这种模式是承接Write-Through的，在对数据进行数据持久化存储回写时一般采用异步回写，也可以间隔一定时间后批量回写
*适用场景*：读少写多
*存在的问题*：异步或间隔一定时间的批量回写会导致数据延迟或数据丢失的情形出现。

这里只是介绍了常见的缓存模式里的一些基本情况，所讨论的缓存模式都存各自的问题，需要我们根据自己的业务场景来选用适合自己的模式。当然数据丢失、热点数据、缓存穿透、缓存预热等这些问题是在使用缓存时都必须考虑的。另外数据模型也是需要注意的，在Cache-Aside下缓存里的数据模型可以与数据库数据模型不一致，而Read/Write-Through模式下二者的数据模型一般是需要相同的。

里面提到了数据一致性一般是多步骤操作时其中一步骤操作失败与并发这两种情况引起的，也介绍了各种方案及问题，比如延迟双删的场景。文章也有提到我们使用redis是为了提高性能，有的时候我们并不能保证完全一致性，只能做到最终一致性，也就是CAP里的AP（可用性与分区容错性，一致性很难）。还有一点就是使用Cache-Aside模式导致不一致的概率是最低的，我们先列下流程：

1. 缓存中X不存在，数据库里X=1
2. 线程A读取数据库，得到旧值X=1
3. 线程B更新数据库X=2，
4. 线程B删除缓存
5. 线程A将旧值X=1写入缓存

### **为什么说Cache-Aside模式导致不一致的概率很低**呢？

原因如下：

1. 读请求 + 写请求并发
2. 缓存刚好已失效
3. 更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5）

只有这三种情况都出现才会出现不致，特别是第3步出现的可能性比较小，因为更新数据的时间可能会有锁，一般会长于读的时间。

一点总结：

1. 引入缓存的目的大部分是为了提升性能
2. 性能与数据强一致性往往很难兼顾
3. 没特殊情况，建议使用先更新数据库+再删除缓存的方式
4. 延迟双删是为了缓存+主从库未及时同步的问题，删缓存操作一般通过消息队列进行，但延迟时间不好评估（先删除缓存，接着修改数据库，最后延迟一定时间再删一次缓存）



--------



- **Cache Aside策略**：应用程序直接**与数据库和缓存交互**，并负责维护缓存的一致性

   - 查询：先查询缓存，如果缓存中没有，则查询数据库，并将结果写入缓存
   - 更新：先更新数据库，然后删除缓存或者更新缓存

- **Read/Write Through策略**：应用程序**只和缓存交互**，而是使用缓存服务与数据库交互

   - 查询：先查询缓存，如果缓存中没有，则缓存服务从数据库中加载数据，并写入缓存
   - 更新：先更新缓存，再由缓存服务同步更新数据库

- **Write Behind 策略**：应用程序**只和缓存交互**。当有数据更新时，**只更新缓存**，不直接更新数据库，改为**异步的方式**更新数据库

- **Refresh-Ahead策略**：应用程序**只和缓存交互**，由后台服务与数据库交互

   - 查询：只查询缓存
   - 更新：由后台服务**自动从数据库中查询最新的数据**，并将数据写入缓存中，

  不同**于以上三种**，应用程序**无需等待**数据的刷新，也无需自己去触发数据的刷新，而是后台服务来完成这些操作

  https://www.cnblogs.com/reim/p/17414244.html



https://javaguide.cn/database/redis/3-commonly-used-cache-read-and-write-strategies.html

### [Cache Aside Pattern（旁路缓存模式）](#cache-aside-pattern-旁路缓存模式)

**Cache Aside Pattern 是我们平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。**

Cache Aside Pattern 中服务端需要同时维系 db 和 cache，并且是以 db 的结果为准。

### [Read/Write Through Pattern（读写穿透）](#read-write-through-pattern-读写穿透)

Read/Write Through Pattern 中服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 db，从而减轻了应用程序的职责。

这种缓存读写策略小伙伴们应该也发现了在平时在开发过程中非常少见。抛去性能方面的影响，大概率是因为我们经常使用的分布式缓存 Redis 并没有提供 cache 将数据写入 db 的功能。

**写（Write Through）：**

- 先查 cache，cache 中不存在，直接更新 db。
- cache 中存在，则先更新 cache，然后 cache 服务自己更新 db（**同步更新 cache 和 db**）。

**读(Read Through)：**

- 从 cache 中读取数据，读取到就直接返回 。
- 读取不到的话，先从 db 加载，写入到 cache 后返回响应。

Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由客户端自己负责把数据写入 cache，而 Read Through Pattern 则是 cache 服务自己来写入缓存的，这对客户端是透明的。



### [Write Behind Pattern（异步缓存写入）](#write-behind-pattern-异步缓存写入)

Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 db 的读写。

但是，两个又有很大的不同：**Read/Write Through 是同步更新 cache 和 db，而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。**

很明显，这种方式对数据一致性带来了更大的挑战，比如 cache 数据可能还没异步更新 db 的话，cache 服务可能就就挂掉了。

这种策略在我们平时开发过程中也非常非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 Innodb Buffer Pool 机制都用到了这种策略。

Write Behind Pattern 下 db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。



----

# 高并发场景下，6种方案，保证缓存和数据库的最终一致性！

郭元锴

[腾讯云开发者](javascript:void(0);)

*2022年01月13日 17:50*

导语 | 到底是更新缓存还是删除缓存? 到底是先更新数据库，再删除缓存，还是先删除缓存，再更新数据库？本文主要介绍了在不同场景下保证数据缓存一致性的相关策略。

**引言**

对于互联网业务来说，传统的直接访问数据库方式，主要通过数据分片、一主多从等方式来扛住读写流量，但随着数据量的积累和流量的激增，仅依赖数据库来承接所有流量，不仅成本高、效率低、而且还伴随着稳定性降低的风险。鉴于大部分业务通常是读多写少（读取频率远远高于更新频率），甚至存在读操作数量高出写操作多个数量级的情况。因此，在架构设计中，常采用增加缓存层来提高系统的响应能力，提升数据读写性能、减少数据库访问压力，从而提升业务的稳定性和访问体验。

根据CAP原理，分布式系统在可用性、一致性和分区容错性上无法兼得，通常由于分区容错无法避免，所以一致性和可用性难以同时成立。对于缓存系统来说，如何保证其数据一致性是一个在应用缓存的同时不得不解决的问题。

需要明确的是，**缓存系统的数据一致性通常包括持久化层和缓存层的一致性、以及多级缓存之间的一致性**，这里我们仅讨论前者。持久化层和缓存层的一致性问题也通常被称为双写一致性问题，“双写”意为数据既在数据库中保存一份，也在缓存中保存一份。对于一致性来说，包含强一致性和弱一致性，强一致性保证写入后立即可以读取，弱一致性则不保证立即可以读取写入后的值，而是尽可能的保证在经过一定时间后可以读取到，在弱一致性中应用最为广泛的模型则是最终一致性模型，即保证在一定时间之后写入和读取达到一致的状态。对于应用缓存的大部分场景来说，追求的则是最终一致性，少部分对数据一致性要求极高的场景则会追求强一致性。

**一、保证最终一致性的策略（Cache Policy）**

为了达到最终一致性，针对不同的场景，业界逐步形成了下面这几种应用缓存的策略。

### **（一）Cache-Aside**

Cache-Aside意为旁路缓存模式，是应用最为广泛的一种缓存策略。下面的图示展示了它的读写流程，来看看它是如何保证最终一致性的。在读请求中，首先请求缓存，若缓存命中（cache hit），则直接返回缓存中的数据；若缓存未命中（cache miss），则查询数据库并将查询结果更新至缓存，然后返回查询出的数据（demand-filled look-aside）。在写请求中，先更新数据库，再删除缓存（write-invalidate）。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODreibG98LshnGbJTDalUKJbIzxoRwTA4P1iaLYe9aKqx03fBax4iaHhxlgw/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

- #### **为什么删除缓存，而不是更新缓存？**

在Cache-Aside中，对于读请求的处理比较容易理解，但在写请求中，可能会有读者提出疑问，为什么要删除缓存，而不是更新缓存？站在符合直觉的角度来看，更新缓存是一个容易被理解的方案，但站在性能和安全的角度，更新缓存则可能会导致一些不好的后果。

首先是**性能**，当该缓存对应的结果需要消耗大量的计算过程才能得到时，比如需要访问多张数据库表并联合计算，那么在写操作中更新缓存的动作将会是一笔不小的开销。同时，当写操作较多时，可能也会存在刚更新的缓存还没有被读取到，又再次被更新的情况（这常被称为缓存扰动），显然，这样的更新是白白消耗机器性能的，会导致缓存利用率不高。而等到读请求未命中缓存时再去更新，也符合懒加载的思路，需要时再进行计算。删除缓存的操作不仅是幂等的，可以在发生异常时重试，而且写-删除和读-更新在语义上更加对称。

其次是**安全**，在并发场景下，在写请求中更新缓存可能会引发数据的不一致问题。参考下面的图示，若存在两个来自不同线程的写请求，首先来自线程1的写请求更新了数据库（step1），接着来自线程2的写请求再次更新了数据库（step3），但由于网络延迟等原因，线程1可能会晚于线程2更新缓存（step4晚于step3），那么这样便会导致最终写入数据库的结果是来自线程2的新值，写入缓存的结果是来自线程1的旧值，即缓存落后于数据库，此时再有读请求命中缓存（step5），读取到的便是旧值。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrX9tkYqibcnrfqzaicuLSu5YicibZic1PbXosgo2FSSHUBWVqibKiawvdY2Oag/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

- #### **为什么先更新数据库，而不是先删除缓存？**

另外，有读者也会对更新数据库和删除缓存的时序产生疑问，那么为什么不先删除缓存，再更新数据库呢？在单线程下，这种方案看似具有一定合理性，这种合理性体现在删除缓存成功，但更新数据库失败的场景下，尽管缓存被删除了，下次读操作时，仍能将正确的数据写回缓存，相对于Cache-Aside中更新数据库成功，删除缓存失败的场景来说，先删除缓存的方案似乎更合理一些。那么，先删除缓存有什么问题呢？

问题仍然出现在并发场景下，首先来自线程1的写请求删除了缓存（step1），接着来自线程2的读请求由于缓存的删除导致缓存未命中，根据Cache-Aside模式，线程2继而查询数据库（step2），但由于写请求通常慢于读请求，线程1更新数据库的操作可能会晚于线程2查询数据库后更新缓存的操作（step4晚于step3），那么这样便会导致最终写入缓存的结果是来自线程2中查询到的旧值，而写入数据库的结果是来自线程1的新值，即缓存落后于数据库，此时再有读请求命中缓存（step5），读取到的便是旧值。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrMibc6h1Z1ib2eMQKeNxmJ6wvKlXnmicRoTCp9dqib8xDy7eAsYgCEqqVSQ/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

另外，先删除缓存，由于缓存中数据缺失，加剧数据库的请求压力，可能会增大缓存击穿出现的概率。

- #### **如果选择先删除缓存，再更新数据库，那如何解决一致性问题呢？**

为了避免“先删除缓存，再更新数据库”这一方案在读写并发时可能带来的缓存脏数据，业界又提出了延时双删的策略，即在更新数据库之后，延迟一段时间再次删除缓存，为了保证第二次删除缓存的时间点在读请求更新缓存之后，这个延迟时间的经验值通常应稍大于业务中读请求的耗时。延迟的实现可以在代码中sleep或采用延迟队列。显而易见的是，无论这个值如何预估，都很难和读请求的完成时间点准确衔接，这也是延时双删被诟病的主要原因。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrWOYHcHcYSbLv0jYnmj3zuPNR9sRQA5zMr9WUyqibB5RjJkMQDbfEvog/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)



#### 那么Cache-Aside存在数据不一致的可能吗？

在Cache-Aside中，也存在数据不一致的可能性。在下面的**读写并发场景下**，首先来自**线程1的读请求在未命中缓存的情况下查询数据库（step1），接着来自线程2的写请求更新数据库（step2），但由于一些极端原因，线程1中读请求的更新缓存操作晚于线程2中写请求的删除缓存的操作（step4晚于step3）**，那么这样便会导致最终写入缓存中的是来自线程1的旧值，而写入数据库中的是来自线程2的新值，即缓存落后于数据库，此时再有读请求命中缓存（step5），读取到的便是旧值。

**这种场景的出现，不仅需要缓存失效且读写并发执行，而且还需要读请求查询数据库的执行早于写请求更新数据库，同时读请求的执行完成晚于写请求。足以见得，这种不一致场景产生的条件非常严格，在实际的生产中出现的可能性较小**。(**因为缓存的写入通常要远远快于数据库的写入**，所以在**实际中很难出现请求 2 已经更新了数据库并且删除了缓存，请求 1才更新完缓存的情况**。)

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrAS03DniaJajgPQOBVibfoViajVEFtBuNQPyCaMw04mqiaV3OTple1QSvMw/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

除此之外，在并发环境下，Cache-Aside中也存在读请求命中缓存的时间点在写请求更新数据库之后，删除缓存之前，这样也会导致读请求查询到的缓存落后于数据库的情况。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrpYkaUjMdIOIv6FvnhdfF2jRbN3x6UTuiaqCxzTNwJtTibm4bmiaObJRibg/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

虽然在下一次读请求中，缓存会被更新，但如果业务层面对这种情况的容忍度较低，那么可以采用加锁在写请求中保证“更新数据库&删除缓存”的串行执行为原子性操作（同理也可对读请求中缓存的更新加锁）。加锁势必会导致吞吐量的下降，故采取加锁的方案应该对性能的损耗有所预期。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODriaTrBia3SuKuyzAh8o9icyxWm0dKNhwNHQic5P3WkxasGe7JhhzNjZibLLw/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrEEnCibyOxNXs1vLVs8TUQdWJkNcLTnTzmKmeQpD1kcYbvZvCrC0czYg/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)



### **（二）补偿机制**

我们在上面提到了，在Cache-Aside中可能存在更新数据库成功，但删除缓存失败的场景，如果发生这种情况，那么便会导致缓存中的数据落后于数据库，产生数据的不一致的问题。其实，不仅Cache-Aside存在这样的问题，在延时双删等策略中也存在这样的问题。针对可能出现的删除失败问题，目前业界主要有以下几种补偿机制。

- #### **删除重试机制**

由于同步重试删除在性能上会影响吞吐量，所以常通过引入消息队列，将删除失败的缓存对应的key放入消息队列中，在对应的消费者中获取删除失败的key，异步重试删除。这种方法在实现上相对简单，但由于删除失败后的逻辑需要基于业务代码的trigger来触发，对业务代码具有一定入侵性。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrnz9eGNonknhW1yKjQUgIr28jHHCOTlUficCA3EZLWlkUzz1G5Y83I4Q/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)



- #### **基于数据库日志（MySQL binlog）增量解析、订阅和消费**

鉴于上述方案对业务代码具有一定入侵性，所以需要一种更加优雅的解决方案，让缓存删除失败的补偿机制运行在背后，尽量少的耦合于业务代码。一个简单的思路是通过后台任务使用更新时间戳或者版本作为对比获取数据库的增量数据更新至缓存中，这种方式在小规模数据的场景可以起到一定作用，但其扩展性、稳定性都有所欠缺。

一个相对成熟的方案是基于MySQL数据库增量日志进行解析和消费，这里较为流行的是阿里巴巴开源的作为MySQL binlog增量获取和解析的组件canal（类似的开源组件还有Maxwell、Databus等）。canal sever模拟MySQL slave的交互协议，伪装为MySQL slave，向MySQL master发dump协议，MySQL master收到dump请求，开始推送binary log给slave（即canal sever），canal sever解析binary log对象（原始为byte流），可由canal client拉取进行消费，同时canal server也默认支持将变更记录投递到MQ系统中，主动推送给其他系统进行消费。在ack机制的加持下，不管是推送还是拉取，都可以有效的保证数据按照预期被消费。当前版本的canal支持的MQ有kafka或者RocketMQ。另外，canal依赖zookeeper作为分布式协调组件来实现HA，canal的HA分为两个部分：

- 为了减少对MySQL dump的请求压力，不同canal server上的instance要求同一时间只能有一个处于运行状态，其他的instance处于standby状态；

- 为了保证有序性，对于一个instance在同一时间只能由一个canal client进行get/ack等动作。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrIHDaicDAicROPsIfQRTWTSp9vvAia6XBfYCPA9TcqJ7dRus700C2iciahRw/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)



那么，针对缓存的删除操作便可以在canal client或consumer中编写相关业务代码来完成。这样，结合数据库日志增量解析消费的方案以及Cache-Aside模型，在读请求中未命中缓存时更新缓存（通常这里会涉及到复杂的业务逻辑），在写请求更新数据库后删除缓存，并基于日志增量解析来补偿数据库更新时可能的缓存删除失败问题，在绝大多数场景下，可以有效的保证缓存的最终一致性。

另外需要注意的是，还应该隔离事务与缓存，确保数据库入库后再进行缓存的删除操作。比如考虑到数据库的主从架构，主从同步及读从写主的场景下，可能会造成读取到从库的旧数据后便更新了缓存，导致缓存落后于数据库的问题，这就要求对缓存的删除应该确保在数据库操作完成之后。所以，基于binlog增量日志进行数据同步的方案，可以通过选择解析从节点的binlog，来避免主从同步下删除缓存过早的问题。

- **数据传输服务DTS**

数据传输服务（Data Transmission Service，简称DTS）是云服务商提供的一种支持RDBMS（关系型数据库）、NoSQL、OLAP等多种数据源之间进行数据交互的数据流服务。DTS提供了包括数据迁移、数据订阅、数据同步等在内的多种数据传输能力，常用于不停服数据迁移、数据异地灾备、异地多活(单元化)、跨境数据同步、实时数据仓库、查询报表分流、缓存更新、异步消息通知等多种业务应用场景。

相对于上述基于canal等开源组件自建系统，DTS的优势体现在对多种数据源的支持、对多种数据传输方式的支持，避免了部署维护的人力成本。目前，各家云服务商的DTS服务已 针对云数据库，云缓存等产品进行了适配，解决了Binlog日志回收，主备切换等场景下的订阅高可用问题。在大规模的缓存数据一致性场景下，优先推荐使用DTS服务。

### **（三）Read-Through**

Read-Through意为读穿透模式，它的流程和Cache-Aside类似，不同点在于Read-Through中多了一个访问控制层，读请求只和该访问控制层进行交互，而背后缓存命中与否的逻辑则由访问控制层与数据源进行交互，业务层的实现会更加简洁，并且对于缓存层及持久化层交互的封装程度更高，更易于移植。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrd2Iep2Jicdb3wH02JCTyIuBPLMXV7pYicnYribuQOU7Lc4zJIwSFpLKtQ/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

### **（四）Write-Through**

Write-Through意为直写模式，对于Write-Through直写模式来说，它也增加了访问控制层来提供更高程度的封装。不同于Cache-Aside的是，Write-Through直写模式在写请求更新数据库之后，并不会删除缓存，而是更新缓存。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrnjqjhjjTeCEXGgTTicXRvlKP6bGG4PEv2Kjjd9Kq1Fic4dGq2DERmC3w/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

这种方式的优势在于读请求过程简单，不需要查询数据库更新缓存等操作。但其劣势也非常明显，除了上面我们提到的更新数据库再更新缓存的弊端之外，这种方案还会造成更新效率低，并且两个写操作任何一次写失败都会造成数据不一致。

如果要使用这种方案，最好可以将这两个操作作为事务处理，可以同时失败或者同时成功，支持回滚，并且防止并发环境下的不一致。另外，为了防止缓存扰动的频发，也可以给缓存增加TTL来缓解。站在可行性的角度，不管是Write-Through模式还是Cache-Aside模式，理想状况下都可以通过分布式事务保证缓存层数据与持久化层数据的一致性，但在实际项目中，大多都对一致性的要求存在一些宽容度，所以在方案上往往有所折衷。

Write-Through直写模式适合写操作较多，并且对一致性要求较高的场景，在应用Write-Through模式时，也需要通过一定的补偿机制来解决它的问题。首先，在并发环境下，我们前面提到了先更新数据库，再更新缓存会导致缓存和数据库的不一致，那么先更新缓存，再更新数据库呢？这样的操作时序仍然会导致下面这样线程1先更新缓存，最后更新数据库的情况，即由于线程1和线程2的执行不确定性导致数据库和缓存的不一致。这种由于线程竞争导致的缓存不一致，可以通过分布式锁解决，保证对缓存和数据库的操作仅能由同一个线程完成。对于没有拿到锁的线程，一是通过锁的timeout时间进行控制，二是将请求暂存在消息队列中顺序消费。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrcX1zSAV12uwknqdLCemqkmXic2GmXm1HeQmBKdW91DEY2RqaDJ1bYmg/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

在下面这种并发执行场景下，来自线程1的写请求更新了数据库，接着来自线程2的读请求命中缓存，接着线程1才更新缓存，这样便会导致线程2读取到的缓存落后于数据库。同理，先更新缓存后更新数据库在写请求和读请求并发时，也会出现类似的问题。面对这种场景，我们也可以加锁解决。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODr2kcjCBCGlsqnBn80yX6zSc0uKHxjxygQSBUWNnJq3DetyhicNzAg1sw/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

### **（五）Write-Behind**

Write behind意为异步回写模式，它也具有类似Read-Through/Write-Through的访问控制层，不同的是，Write behind在处理写请求时，只更新缓存而不更新数据库，对于数据库的更新，则是通过批量异步更新的方式进行的，批量写入的时间点可以选在数据库负载较低的时间进行。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrMiaFPO7oaAkRD1k8eGjVx9aicEjahibQsPP8lRaMiczbzhMibBSU2Qo4ZOQ/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

在Write-Behind模式下，写请求延迟较低，减轻了数据库的压力，具有较好的吞吐性。但数据库和缓存的一致性较弱，比如当更新的数据还未被写入数据库时，直接从数据库中查询数据是落后于缓存的。同时，缓存的负载较大，如果缓存宕机会导致数据丢失，所以需要做好缓存的高可用。显然，Write behind模式下适合大量写操作的场景，常用于电商秒杀场景中库存的扣减。

### **（六）Write-Around**

如果一些非核心业务，对一致性的要求较弱，可以选择在cache aside读模式下增加一个缓存过期时间，在写请求中仅仅更新数据库，不做任何删除或更新缓存的操作，这样，缓存仅能通过过期时间失效。这种方案实现简单，但缓存中的数据和数据库数据一致性较差，往往会造成用户的体验较差，应慎重选择。

**二、总结**

在解决缓存一致性的过程中，有多种途径可以保证缓存的最终一致性，应该根据场景来设计合适的方案，读多写少的场景下，可以选择采用“**Cache-Aside结合消费数据库日志做补偿**”的方案，写多的场景下，可以选择采用“**Write-Through结合分布式锁**”的方案，写多的极端场景下，可以选择采用“**Write-Behind**”的方案。



注：Cache-Aside，

#### 那么Cache-Aside存在数据不一致的可能吗？

在Cache-Aside中，也存在数据不一致的可能性。在下面的**读写并发场景下**，首先来自**线程1的读请求在未命中缓存的情况下查询数据库（step1），接着来自线程2的写请求更新数据库（step2），但由于一些极端原因，线程1中读请求的更新缓存操作晚于线程2中写请求的删除缓存的操作（step4晚于step3）**，那么这样便会导致最终写入缓存中的是来自线程1的旧值，而写入数据库中的是来自线程2的新值，即缓存落后于数据库，此时再有读请求命中缓存（step5），读取到的便是旧值。

**这种场景的出现，不仅需要缓存失效且读写并发执行，而且还需要读请求查询数据库的执行早于写请求更新数据库，同时读请求的执行完成晚于写请求。足以见得，这种不一致场景产生的条件非常严格，在实际的生产中出现的可能性较小**。

![图片](https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94fDAJKuwQUQlzM68vU3ODrAS03DniaJajgPQOBVibfoViajVEFtBuNQPyCaMw04mqiaV3OTple1QSvMw/640?wx_fmt=png&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)
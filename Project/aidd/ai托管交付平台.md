# ai托管交付平台
## 难点
+ 整体的编码Agent如何运作来写出代码？（prompt+LLM流程+工具集）
+ codebase代码如何召回？
+ 代码生成代码后，apply速度很慢 （代码编辑）
+ 代码写完后如何进行编译，确定AI生成的代码没有语法错误（代码编译）
+ 效果如何测评？

## 背景现状
构建一个 AI 驱动的端到端需求托管交付平台，实现“用户在web端界面输入需求描述，AI 自主完成从需求分析、编码到测试的全流程”，降低 PD、开发、测试等角色在中间环节的介入成本。用户包括（PD、开发、测试）同学。

+ 需求Agent：接收用户产品需求文档（自然语言形式提交），自动解析，输出可执行的开发功能点与对应的测试功能点，完成需求拆解与任务分发。
+ 编码Agent：基于需求 Agent 产出的开发功能点，自动生成高质量、可运行的代码以及代码思路。
+ 测试Agent：在代码成功部署后，依据测试功能点自动创建测试用例、执行自动化测试（包括接口、UI、回归等），生成完整的测试报告。

## 技术架构
### LLM流程
#### 主流程LLM Prompt
+ <u>选用了langengine框架（非常灵活，所有都可以由自己控制），借助了框架里的上下文对象和 llm交互的生命周期函数(`onChainStart/onLlmStart/onToolStart`)，相当于这个框架提供了模版类，不用自己写模版了。
+ 调大模型的接口，我们内部有一个朱雀网关提供了sdk包。
+ 流程编排ReAct模式：开启死循环，循环里面LLM思考，思考完成后调工具，工具结果作为上下文继续下一轮LLM思考，思考完成后再调工具，直到出错或者工具名称为空就代表结束。</u>

```java
public class AiAgent extends AbstractRequestAgent {
    private ExecutionContext initExecutionContext(String query, String sessionId, String conversationId, CodeInfo codeInfo) {
        ExecutionContext executionContext = new ExecutionContext();
        executionContext.setChain(new LLMChain());
        executionContext.getChain().setCallbackManager(new MainAgentCallBackManager());
        return executionContext;
    }

    public AgentDetailBO execute(String query, CodeInfo codeInfo, String sessionId) throws Exception {
        String conversationId = UUID.randomUUID().toString();
        // 初始化agent的上下文信息
        ExecutionContext executionContext = initExecutionContext(query, sessionId, conversationId, codeInfo);
        AgentDetailBO result = ...
        BaseCallbackManager callbackManager = executionContext.getChain().getCallbackManager();

        ChatStopObserver chatStopObserver = new ChatStopObserver(sessionId);
        try {
            STOP_OBSERVABLE.addObserver(chatStopObserver);
            List<BaseChatMessage> chatMessages = initMessages(codeInfo, sessionId);
            callbackManager.onChainStart(executionContext);
            while (true) {
                callbackManager.onLlmStart(executionContext);
                try {
                    LlmResponse llmResponse = runStream(query, chatMessages, chatStopObserver);
                    if (chatStopObserver.getStop()) {
                        return result;
                    }
                    executionContext.setLlmResult(llmResponse);
                    callbackManager.onLlmEnd(executionContext);
                    chatMessages.add(llmResponse);
                    if (StringUtils.isBlank(llmResponse.getFunctionName())) {
                        result.setLlmOutput(llmResponse.getOutput());
                        break;
                    }
                    String functionName = llmResponse.getFunctionName();
                    if (StringUtils.isNotBlank(functionName)) {
                        // 执行工具
                        callbackManager.onToolStart(executionContext);
                        MyToolExecuteResult toolResult = addFunction.calAop(executionContext);
                        // 保存状态
                        callbackManager.onToolEnd(executionContext);
                        chatMessages.add(toolResult);
                        if (toolResult == null || toolResult.isInterrupted()) {
                            break;
                        }
                    }
                } catch (Throwable e) {
                    executionContext.setThrowable(e);
                    callbackManager.onLlmError(executionContext);
                    break;
                }
            }
        } catch (Exception e) {
            executionContext.setThrowable(e);
            callbackManager.onChainError(executionContext);
        } finally {
            STOP_OBSERVABLE.deleteObserver(chatStopObserver);
            callbackManager.onChainEnd(executionContext);
            callbackManager.onAgentFinish(executionContext);
        }
        return result;
    }
}

```

#### 任务未完成即结束
出现LLM思考后没工具调后返回或常提前退出，但任务没完成任务。

+ <u>LLM 的“幻觉”或误判：LLM 可能认为它已经通过前面的对话或者工具结果得到了答案，但实际上那些信息是解决用户任务的。</u>
    > 例子：你让它修复一个 Bug，它调了 grep 没搜到结果，于是直接回复：“我没找到相关代码，该 Bug 可能不存在或已修复。” 此时工具调用为空，循环结束，但你的任务（修复 Bug）并没做。
    
+ <u>达到上下文长度限制</u>

+ <u>陷入死循环后的自动逃逸：如果 LLM 在前几次迭代中发现反复调用同一个工具且结果不理想（比如文件一直打不开），它为了打破这种无效循环，可能会选择不再调用该工具，转而输出一段道歉或说明文字。</u>

+ 提示词没有强烈要求“未达成目标前严禁停止”：LLM 可能会在遇到困难时选择“认输”或“绕道”。它会给一段文字解释为什么没做，这段文字会被当做 llmResponse.getOutput() 返回，逻辑依然会 break。

在现有的 死循环写法 下，通常有几种优化手段：
+ <u>（最优）增加校验节点：在循环结束前，增加一轮专门的 LLM 判定，`根据目前所有的工具结果，判断任务‘XXX’是否真的已经彻底完成？如果没有，请继续调用工具。`</u>
+ 强制性指令：在 Prompt 中明确要求：“在给出最终结论前，你必须调用验证类run_test工具确保你的改动是有效的。”
+ 设置最大迭代次数 + 最小成功动作数
    + 最多执行 N 轮（如 10 次），防止死循环
    + （AI项目）要求至少完成 K 个关键工具（如“必须调用过 code_edit 且 get_diagnostics 返回无 error”）才允许退出。

### Prompt
#### Cusor Agent 模式Prompt
```
----------- 角色介绍 -----------
你是一个强大的代理型AI编程助手（agentic AI coding assistant），由Claude 4 Sonnet提供支持。
你专门在Cursor（世界上最佳的IDE）中运行。

----------- 目标和任务 1-----------
1. 你正在与用户进行结对编程（pair programming）来解决他们的编码任务。
2. 该任务可能需要创建新的代码库、修改或调试现有代码库，或者仅回答问题。 
3. 每次用户发送消息时，我们可能会自动附加一些关于他们当前状态的信息，如已打开的文件、光标位置、最近查看的文件、会话中的编辑历史、代码检查器（linter）错误等。
4. 这些信息可能与编码任务相关或不相关，由你来判断。 你的主要目标是遵循用户在每条消息中通过<user_query>标签表达的指示。

----------- AI 使用工具调用时遵守的规则 1+2+4 -----------
<tool_calling> 
你可以使用工具来解决编码任务。关于工具调用，请遵循以下规则：
1. 始终严格按照指定的工具调用模式执行，并确保提供所有必要参数。
2. 对话中可能会提及不再可用的工具。切勿调用未明确提供的工具。
3. 与用户交流时切勿提及工具名称。例如，不要说"我需要使用edit_file工具来编辑你的文件"，只需说"我将编辑你的文件"。
4. 只在必要时调用工具。如果用户的任务较为宽泛或你已经知道答案，直接回应而不调用工具。
5. 在调用每个工具之前，先向用户解释为什么要调用它。 
</tool_calling>

----------- AI 使用工具调用参数遵守的规则 1+2+3 -----------
使用相关工具（如果可用）回答用户的请求。
1. 检查每个工具调用的所有必需参数是否都已提供或可以从上下文中合理推断。
2. 如果没有相关工具或缺少必需参数的值，请要求用户提供这些值；否则继续进行工具调用。
3. 如果用户为参数提供了特定值（例如在引号中提供），请确保精确使用该值。不要为可选参数编造值或询问这些参数。
4. 仔细分析请求中的描述性术语，因为它们可能表示即使未明确引用也应包含的必需参数值。

----------- AI 修改代码时遵守的规则 7-----------
<making_code_changes> 
在进行代码更改时，除非用户明确要求，否则切勿向用户输出代码。请使用代码编辑工具来实现更改。 每轮对话最多使用一次代码编辑工具。 确保你生成的代码可以被用户立即运行，这一点极其重要。为确保这一点，请仔细遵循以下指导：
1. 始终将对同一文件的编辑分组在单个edit file工具调用中，而非多次调用。
2. 如果你从零开始创建代码库，请创建适当的依赖管理文件（例如requirements.txt），包含包版本和有用的README。
3. 如果你从零开始构建Web应用，请赋予它美观现代的UI，融入最佳用户体验（UX）实践。
4. 切勿生成极长的哈希值或任何非文本代码，如二进制代码。这些对用户没有帮助且非常耗费资源。
5. 除非你是在文件中添加一些小型易于应用的编辑，或者创建新文件，否则在编辑之前，你必须阅读你正在编辑的内容或部分。
6. 如果你引入了（代码检查器）错误，若清楚如何修复（或能够轻松弄清楚如何修复），就进行修复。
7. 不要做无根据的猜测。并且在同一文件上修复代码检查器错误时不要循环超过3次。第三次时，你应该停止并询问用户下一步该怎么做。
8. 如果你提出了一个合理的code_edit但未被模型应用，你应该尝试重新应用该编辑。
</making_code_changes>

----------- AI 检索代码时遵守的规则 1+2-----------
<searching_and_reading> 
你有工具可以搜索代码库和读取文件。关于工具调用，请遵循以下规则：
1. 如果可用，强烈优先使用语义搜索工具而非grep搜索、文件搜索和目录列表工具。
2. 如果你需要阅读一个文件，优先一次读取文件的较大部分，而非多次读取较小部分。
3. 如果你已经找到了合理的编辑位置或答案，不要继续调用工具。根据你找到的信息进行编辑或回答。 
</searching_and_reading>

----------- 工具集(包含代码块引用格式) -----------
<functions>
<function></function>
</functions>

引用代码区域或块时，你必须使用以下格式：
... existing code ...
这是引用代码的唯一可接受格式。格式为```startLine:endLine:filepath，其中startLine和endLine是行号。

----------- 用户信息 -----------
<user_info> 
用户的操作系统版本是win32 10.0.26100。用户工作区的绝对路径是/c:/Users/Lucas/Downloads/luckniteshoots。用户的shell是C:\WINDOWS\System32\WindowsPowerShell\v1.0\powershell.exe。 
</user_info>
```

#### 评价
**优点**
+ <u>明确的工具调用规则</u>：详细列出了工具调用的规则和注意事项，避免了滥用工具或调用无关工具。
+ <u>搜索和读取的优化：提供了多种搜索工具，并建议优先使用语义搜索，</u>同时对文件读取的范围和方式进行了优化，避免了不必要的性能浪费。
+ <u>代码生成的严格性：对代码修改的格式和步骤有严格要求，</u>确保代码质量和用户体验。
+ <u>错误处理机制：</u>在代码修改中引入了错误处理机制，例如限制修复代码检查器错误的次数，并在必要时询问用户意见。
+ <u>用户友好性：强调了与用户沟通的重要性，</u>例如在调用工具前解释原因，避免提及工具名称以降低用户的学习成本。

**缺点**
+ <u>对用户太依赖性（协作式）：在缺少必要参数时需要用户补充</u>，可能导致交互过程中的延迟或中断。
+ 规则过于复杂：提示词中包含大量规则和注意事项，可能导致理解和记忆的难度较大。
+ 工具调用的限制：虽然规则有助于规范操作，但过于严格的限制可能在某些情况下限制了灵活性，例如在某些紧急任务中可能需要更快地调用工具。
+ 代码修改的限制：对代码修改的限制较多，例如每次只能使用一次代码编辑工具，可能会在复杂任务中降低效率。
+ 工具功能的局限性：虽然提供了多种工具，但某些工具（如语义搜索）可能在某些情况下不够精确，需要进一步

#### 自主式Prompt
<u>因为是web端，用户交互在产品上只设计了两轮交互，`“输入功能拆解点” 和 “提交修改建议”`。我们的场景不需要协作式，而是自主式，能够主动推进。所以prompt里加入了：

+ 流程上侧重：`"持续处理直到问题被完全解决后，再交还控制权给用户"`
+ 工具调用侧重：`“需要额外的信息时优先使用工具而非问用户”、“制定了计划，立即执行，不要等待确认”, 允许“自主读取任意数量的文件来澄清自己的疑问”`
+ 出错时侧重：`“继续收集更多信息或使用更多工具”、“优先自己解决问题，而不是向用户求助”`</u>
+ 代码编辑时侧重：`“生成的代码必须可以被用户立即运行”`

### 工具集
+ <u>用于文件读取：
    + 读文件内容工具read_file：可读项目文件
    + 读文件夹工具：读文件夹下一级目录工具list_dir、读文件夹下级所有目录工具list_package(自创)
+ 用于内容检索：
    + 代码语义检索工具codebase_search：混合检索
    + 代码检索工具：精确搜索或正则模糊搜索文本内容工具grep_search、搜索类信息工具read_class(自创)、搜索方法信息工具read_method(自创)
    + 文件名称检索工具file_search：模糊搜索文件名
+ 用于代码类：
    + 代码编辑工具
    + 代码编译工具</u>
    

#### 读取文件内容工具 read_file
**作用：**
提供强大的文件内容获取能力，包括。
+ 按行区间读取：支持指定行号范围精确读取文件内容。
+ 读取文件后按文件内容筛选过滤。
+ ~~跨项目支持：不仅支持当前项目文件，还能读取导入的二方包、三方包内的源码。~~
+ ~~长文件自动获取文件摘要：包含所有方法名，返回值以及行区间信息，避免模型一次性读太多。~~

**prompt：**
```
读取文件的内容。
此工具调用的输出将是从 start_line_one_indexed 到 end_line_one_indexed_inclusive 的 索引文件内容，以及 start_line_one_indexed 和 end_line_one_indexed_inclusive 之外的行的摘要。
```

**入参：**

|              名称               |   类型   |                             描述                             |
| ------------------------------ | ------- | ----------------------------------------------------------- |
| target_file                    | String  | 要读取的文件的路径                                             |
| keywordRegex                   | String  | 用于过滤文件内容的关键字。类型为正则表达式。如果不需要过滤，则传递'\*' |
| should_read_entire_file        | Boolean | 是否读取整个文件。默认为 false                                  |
| start_line_one_indexed         | Integer | 开始读取的行号（含）                                            |
| end_line_one_indexed_inclusive | Integer | 结束读取的行号（含）                                            |
| explanation                    | String  | 用一句话解释为什么使用这个工具，以及它如何有助于实现目标              |

**原理：**
cat 后 用grep -E 过滤
``` shell
if [ ! -f "$target_file" ]; then
    echo "File not found"
    exit 1
fi

cat "$target_file" | grep -E "$keywordRegex"


awk 'NR<5 {
    print "[前面还有" (5-NR) "行]"
    exit
}
NR>=5 && NR<=10 {
    print
}
NR>10 {
    print "[后面还有" (NR-10) "行]"
    exit
}' "$target_file"
```



#### 罗列文件夹下一级目录工具 list_dir
**作用：**
罗列指定的文件夹的下一级目录

**prompt：**
```
列出目录内容。在使用语义搜索或文件读取等更有针对性的工具之前，这是一个快速发现的工具。
在深入研究特定文件之前，它有助于理解文件结构。也可用于探索代码库。
```
**入参：**

| 名称 | 类型 | 描述 |
| --- | --- | --- |
relative_workspace_path     | String    |  要搜索的目录(相对路径)   |
|  explanation   |  String   |  用一句话解释为什么使用这个工具，以及它如何有助于实现目标。   |

**原理：**
用ls命令
`ls -1 %s | sed 's|^|%s/|`

#### 罗列文件夹下级所有目录工具 list_package
**作用：**
罗列指定的文件夹的下级所有目录

**prompt：**
```
这最适合查询项目包结构
当目标是了解整体文件结构而不是定位特定文件时，应优先使用此工具。
```
**入参：**

| 名称 | 类型 | 描述 |
| --- | --- | --- |
relative_workspace_path     | String    |  要搜索的目录(相对路径)   |
|  explanation   |  String   |  用一句话解释为什么使用这个工具，以及它如何有助于实现目标。   |

**原理：**
用 find 找出指定目录下所有非隐藏目录
`find %s -type d -not -path '*/\.*' \
 | sed 's|%s||g' | sort`


#### 模糊搜索文件名工具 file_search
**作用：**
按模糊的名字来搜索文件名

**prompt：**
```
基于文件路径模糊匹配的快速文件搜索。
如果您知道部分文件路径，但不知道其确切位置，请使用此功能。
```

**入参：**

| 名称 | 类型 | 描述 |
| --- | --- | --- |
fuzzyFilename     | String    |  要搜索的模糊文件名   |
|  explanation   |  String   |  用一句话解释为什么使用这个工具，以及它如何有助于实现目标。   |

**原理：**
用find命令到指定目录下按正则表达式来搜文件

`find /Users/chenzelei/Desktop/chenzeleitest/aidd/code/master -type f -iname '*GrepSearchShell*' | grep -v '\.class$' | grep -v '/target/' | sed 's|/Users/chenzelei/Desktop/chenzeleitest/aidd/code/master/||g'`


#### 精确搜索或正则模糊搜索文本内容工具 grep_search
**作用：**
按关键词精准搜索 或 正则表达式模糊 文本内容

**prompt：**
```
这最适合查找精确的文本匹配或正则表达式模式。
当我们知道确切的符号/函数名称/等，这比语义搜索更受欢迎。
在一组目录/文件类型中搜索。
使用此工具，可以使用 grep 命令对文本文件进行快速、精确的正则表达式搜索。为避免输出过多，结果限制为 50 个匹配项。
使用包含或排除模式，按文件类型或特定路径过滤搜索范围。不执行模糊或语义匹配。仅返回有效的正则表达式字符串。
```

**入参：**

|       名称       |   类型   |                         描述                          |
| --------------- | ------- | ---------------------------------------------------- |
| query           | String  | 搜索的精准文本 或 正则表达式                             |
| case_sensitive  | Boolean | 搜索是否区分大小写                                      |
| include_pattern | String  | 要包含的文件的通配符模式（例如 '\*.java' 表示 Java 文件）   |
| exclude_pattern | String  | 要排除的文件的通配符模式（例如 '*.test.java' 表示测试文件） |
| explanation     | String  | 用一句话解释为什么使用这个工具，以及它如何有助于实现目标      |

**原理：**
用grep命令在指定的文件范围里，搜索文本内容
`grep -Eirn -m 50 --include=*.java "$query" /Users/chenzelei/Desktop/chenzeleitest/aidd/code/master | head -n 50`

#### 搜索类信息工具 read_class
**作用：**
直接查询类的信息，在知道类名情况下优先使用。

**prompt：**
```
快速查询java类基本信息的工具,在明确知道类名的前提下,优于read_file
```

**入参：**
|       名称       |   类型   |                         描述                          |
| --------------- | ------- | ---------------------------------------------------- |
| clazzName           | String  | java类名(批量,隔开),不支持枚举类                               |
| totalFlag  | Boolean | 是否需要返回类的imports和类中的全局变量、全局常量，只有必须查询的时候才设置成true                                      |


**原理：**
从内存里直接读到对应java的类代码块

#### 搜索方法信息工具 read_method
**作用：**
直接查询方法的信息，在知道方法名的情况下优先使用。

**prompt：**
```
查询方法的调用信息和源码信息,在有方法名的时候优先执行, 优于read_file和grep_search
```

**入参：**
|       名称       |   类型   |                         描述                          |
| --------------- | ------- | ---------------------------------------------------- |
| clazzName           | String  | java类名(批量,隔开)                               |
| method  | String | 是否要同时查询上下游调用的方法                                      |
| filedFlag  | Boolean | 是否需要类的fields信息                                      |
| importFlag  | String | 是否需要类的import的信息                                      |


**原理：**
从内存里直接读到对应java类的方法的代码块

#### 语义检索工具 codebase_search
**作用：**
召回跟 query相关的代码片段

**prompt：**
```
从代码库中查找与搜索查询最相关的代码片段/类/方法。
这是一个语义搜索工具，因此查询应该在语义上与所需内容匹配。除非有明确的理由使用您自己的搜索查询，否则请重复使用用户的精确查询及其措辞。他们的精确措辞/措辞通常对语义搜索查询很有帮助。保持完全相同的问题格式也会有帮助。
```

**入参：**

|     名称     |  类型   |                       描述                       |
| ----------- | ------ | ----------------------------------------------- |
| query       | String | 用于查找相关代码的搜索词，AI优化过的词                |
| explanation | String | 用一句话解释为什么使用这个工具，以及它如何有助于实现目标 |


**原理：**
<u>作用：检索不一定需要 100 % 准确，更多的还是先通过检索定位到大致的文件，然后让 Agent 去细读相关文件的逻辑。
跟准确度相关性不大：检索召回本身只是一个做粗略定位的中间流程，最终的准确与否不完全取决于召回情况。

实现：在粗召回阶段采用多路召回，分中文召回（中文需求召回、中文关键词召回）和英文召回（英文需求召回、英文关键词召回）。在召回的基础，使用自适应聚类进行分组，再结合基于 LLM 的精排打分机制精排。</u>

##### 中找中(粗召回)
###### chunk
+ <u>给每一个方法</u>（输入是方法名+带注释的源码+方法内field字段）<u>生成注释</u>
    + <u>一句话的方法概括性注释</u>，作为一个Chunk
    + <u>分点过程的注释，有效提炼代码分支（如if，for等）</u>，每一个点作为一个Chunk
    + <u>整个方法的关键词</u>，用来做关键词召回
> + <u>如果是抽象方法，先生成实现方法。</u>生成完实现方法后，再加入实现方法的注释。例如`xxx()实现了这个方法`
> + <u>如果有调用关系，被调用的方法未分析，那么先分析被调用的方法</u>；分析过则加入被调用的方法注释

+ <u>给每一个类</u>（输入是父类/接口名称和注释 + 类名 + imports + field字段 + 方法详情(方法签名+代码+注释)）<u>生成注释</u>
    + <u>一句话的类概括性注释</u>，作为一个Chunk
    + <u>分点归纳的注释</u>，每一个归纳作为一个Chunk
 
###### 混合搜索介绍(Tis3Plus 召回引擎版)
+ (稠密)向量召回（语义搜索）
+ [混合向量](https://aliyuque.antfin.com/arr480/fbefv0/im6lfb5626p1dz6k) = 稠密向量（语义搜索） + 稀疏向量（关键词搜索）
    + 稠密向量：用深度学习模型（如 BERT）将文本转为稠密向量，<u>即使文字不同但语义相近也能召回。可能会漏掉那些包含关键术语但表述方式与查询语义不同的文档。</u>
    + 稀疏向量：</u>保留传统关键词匹配能力</u>（如 TF-IDF、BM25 的思想），强调词频、重要性等。<u>但因无法理解用户查询的真实意图，无法召回同义词。</u>`{"indices": [16, 18, 102, ...], "values": [0.21, 0.11, 0.15, ...]}`
    > <u>Tis3Plus 召回引擎版的混合索引不是“多路召回再融合”，而是 将稀疏向量和稠密向量组合成一个统一的向量结构进行索引和检索。</u>
    > + <u>传统多路召回做法：分别用关键词和向量多路召回结果，再合并打分。</u>
    > + <u>Tis3Plus做法：在索引阶段就把稀疏+稠密向量“嵌入”到同一个字段中，查询时也传入混合向量，系统内部完成融合计算。</u>

+ [文本召回（关键词搜索）](https://tisplus3-document.io.alibaba-inc.com/docs/召回引擎版/最佳实践/排序相关/通过pack索引实现文本相关性排序)：
    + <u>and召回表示文本内容分词后的term全匹配召回（默认）；OR召回表示文本内容分词后的term匹配上一项就召回</u>[and or介绍](https://tisplus3-document.io.alibaba-inc.com/docs/召回引擎版/查询语法/DSL语法/DSL查询子句语法/config子句)
    + 分词器有：中文通用分词器和英文分词器
    + <u>排序逻辑是：（前100w条数据）进行粗排、（前200条）进行精排</u>
    
###### Embedding
+ <u>建立一个向量召回索引（`距离类型InnerProduct, 向量索引算法 HNSW`），将每一个Chunk embeddding（`text-embedding-v3 默认且最大的1024维`）后，存入向量数据库。</u>
    > text-embedding-v3是当时最新的千问模型了
    > InnerProduct+HNSW 适合衡量方向相似性场景
+ <u>建立一个文本召回，将每一个方法的所有关键字，存入向量数据库。（`引入文本召回是解决高频词霸权问题`）</u>

|      维度       |          Squared Euclidean + QC（量化类索引）           |             InnerProduct + HNSW              |
| --------------- | ---------------------------------------------------- | -------------------------------------------- |
| 距离计算类型      | Squared Euclidean采用欧氏距离的平方                     | InnerProduct采用内积，模拟余弦相似度             |
| 向量索引算法      |                                                      | HNSW基于图的高效近似最近邻（ANN）索引             |
| 是否归一化敏感    | 不要求向量归一化                                        | 若用内积模拟余弦相似度，需对向量 L2 归一化         |
| 召回率（Recall） | 中等（依赖量化精度）                                     | 通常很高（可调参数如 ef, M 控制精度）             |
| 适合场景         | 适合衡量绝对位置差异(图像检索、非归一化特征、需要精确几何距离) | 适合衡量方向相似性场景(语义搜索、推荐系统、文本匹配) |


###### 中文召回的问题
**项目初始化生成时间长**
<u>因为基于LLM+prompt生成代码描述。</u>以risk-platform应用为例，代码块纬度方法16335个，生成时间3h起步。
> 初次是并行加速 + 缓存，增量git diff部分

**高频词霸权问题**
+ <u>核心动词被高频名词淹没，如：`“用户删除订单” vs “用户查询订单”`—— 二者共现词“订单”相同，但动作语义（新增vs 查询）截然不同
+ 原因：“订单” 在代码库中高频共现，其向量成为“语义引力中心”，导致所有含 “订单” 的代码块在向量空间中被错误拉近</u>
+ <u>后果：向量距离失真 → 无关结果占据 topK（假阳性），真正匹配“用户查询订单”代码被淹没。</u>
+ <u>解法：强化动作语义，抑制高频词干扰
    + 构建文本召回，通过 BM25 等算法天然对高频词降权，</u>能抑制核心关键词“订单”的影响力，突出真正有区分度的动词
    + <u>文本召回时，取and逻辑，都满足term才算匹配成功</u>
    
**结构同质问题**
+ <u>句式高度相似但语义相反或无关，如：`“用户删除订单” vs “用户查询订单”`</u>
+ <u>原因：模型对动词敏感度不足，过度关注高频名词（如“用户”“订单”），忽略动作语义差异。</u>
+ <u>后果：向量距离小 → 误召回（假阳性）。
+ 解法：强化动词语义
    + 引入文本召回，用and逻辑加强动词权重。
    + Rerank里引入动词余弦相似性 ~~+ 用CodeBert模型捕捉需求和代码语义~~</u>
    
**同义异构问题**
+ <u>语义相同但句式不同（主动/被动、主宾调换等），如：`“用户创建订单” vs “订单被用户创建”`</u>
+ 原因：通用 embedding 模型（如  BERT、text-embedding-ada-002）未对谓词-论元结构建模，仅依赖表面词序和上下文共现统计。
+ <u>后果：向量距离大 → 召回失败。（假阴性）</u>
+ <u>解法：提升语义泛化
    + 引入文本召回，去除“主动被动”和“主宾”关系。
    + Rerank里引入CodeBert模型捕捉需求和代码语义 ~~+ 动词余弦相似性~~</u>



##### 英找英(粗召回)
###### 代码chunk
**主流chunk对比：**
+ 按字符/词/行切分：容易把函数劈成两半
+ 固定 token 数切分：容易把函数劈成两半
+ 递归分割 或基于 AST 切分：会基于代码的语义切分


**论文介绍：**
[CAST(Chunking via Abstract Syntax Trees) ](https://arxiv.org/pdf/2506.15655) 在解决代码生成中检索增强生成（RAG）的分块（Chunking）问题。该研究由卡内基梅隆大学（CMU）和 Augment Code 的研究人员共同完成。

原理：
+ <u>AST 解析：利用 Tree-sitter 库将源代码解析为抽象语法树（AST），识别出函数、类、循环等语法单元作为AST节点。</u>
+ 递归分割与合并：
    + 自顶向下遍历：<u>优先尝试将大的 AST 节点作为一个整体放入块中。</u>
    + 递归分割：<u>如果节点过大</u>超过字符限制（默认2000字符），则<u>递归地将其子节点拆分。</u>
    + 相邻合并：为了防止产生过多细碎的小块（如单行导入语句），<u>合并相邻的小的兄弟节点，以最大化每个块的信息密度。</u>
```
遍历每个 AST 节点:
    如果 当前节点 + 当前窗口 ≤ 单窗口最大容量:
        → 将当前节点加入当前窗口
    如果 当前节点 > 单窗口最大容量:
        → 递归拆解当前节点的子节点
    否则:
        → 提交当前窗口，开新窗口
```

性能提升：
+ <u>检索性能：在 RepoEval 上，Recall@5 提升了 4.3%。</u>
+ 生成性能：在 SWE-bench 上，Pass@1 提升了 2.67%。
+ 跨语言一致性：在 CrossCodeEval 上实现了最高 4.3%的增益。


###### 关键词列表生成(方法级别)
<u>从方法签名中以下字段：
+ 方法名称
+ 返回类型：非基本类型；如果是范型则取范型内的`T`
+ 每个入参的类型和变量名称：非基本类型；如果是范型则取范型内的`T`</u>

但要过滤以下内容：
+ jdk内置类型：如`long、Map、String`
+ 框架类：如`HttpServletRequest`
+ 特殊方法：如`<init>、<clinit>`

###### Embedding
+ 建立一个向量召回索引（`距离类型InnerProduct, 向量索引算法 HNSW`），<u>将每一个函数执行 CAST 算法，分成多块，每一块 embeddding</u>（`text-embedding-v3 默认且最大的1024维`）后，存入向量数据库。
+ <u>建立一个文本召回，将每一个方法的关键字列表，存入向量数据库。</u>


###### 生成项目词典库(用于改写)
<u>用来生成项目级的项目词典库。</u>生成的数据来源于 `所有方法的关键词列表` 和 `目录树结构(所有.java文件的全路径类名，并转为树结构)`

+ <u>所有方法的关键词列表 LLM处理逻辑：
    + 驼峰命名法拆分</u>：`createRiskBill`  -> `create`, `Risk`, `Bill`
    + 要过滤，规则是过滤掉 `*DTO、通用框架(如Spring)、通用属性(如Name)、非核心操作动词(如set)`
    + <u>识别出领域名词和领域动词（英文和中文的解释）</u>
    
```
领域名词词典 (Nouns)
+ Agent: 智能代理，负责执行特定的软件开发任务，如代码生成、代码分析等
+ ChatClient: 聊天客户端，用于与用户进行交互，接收指令并返回结果
领域动词词典 (Verbs)
+ Execute: 执行特定任务或计划（关联名词：Plan, Task）
+ Generate: 生成代码、文档或解决方案（关联名词：Code, Document, Plan）
```

+ <u>目录树结构 LLM处理逻辑：</u>
    + 要过滤，规则如上 
    + <u>包路径分析并拆分，提取名词和动词</u>：`com.cainiao.iwant.dacu.riskplatform` -> `dacu`, `riskplatform`
     + <u>从类名、接口名、枚举类型识别领域名词和动词</u>
     
```
领域名词词典 (Nouns)
+ Agent: 系统中代表AI代理的核心概念，负责执行各种开发任务（模块/包：aidd-start、aidd-service）
+ RAG(Retrieval-Augmented Generation): 结合检索和生成的AI技术，用于代码辅助生成（模块/包：aidd-rag）
领域动词词典(Verbs)
+ Generate: 创建特定代码元素，如生成方法或代码建议（关联名词：Code、Method）
+ Parse: 解析代码或响应，将原始数据转换为结构化信息（关联名词：Code、Response）
```

**最终结果：**
```
{
    "core_domain": "智能化软件开发与维护平台",
    "ubiquitous_language_dictionary": {
        "nouns": [
            {
                "name": "Agent",
                "definition": "智能代理，负责执行特定的软件开发任务，如代码生成、代码分析等",
                "context": "aidd-start、aidd-service",
                "sources": [
                    "术语分析",
                    "Maven结构"
                ]
            },
            {
                "name": "ChatClient",
                "definition": "聊天客户端，用于与用户进行交互，接收指令并返回结果",
                "context": "",
                "sources": [
                    "术语分析"
                ]
            },
            {
                "name": "CodeGraph",
                "definition": "代码知识图谱，表示代码间的结构和关系",
                "context": "aidd-code-graph",
                "sources": [
                    "Maven结构"
                ]
            }
        ]
    },
    "consistency_analysis": {
        "conflicts": [
            {
                "term": "Execution",
                "details": "术语 'Execution' 在术语分析中定义为 '执行过程'，但在Maven结构中作为 '执行记录' 出现在 aidd-dal 模块下，可能存在上下文不匹配。",
                "suggestion": "请与领域专家确认 'Execution' 在 aidd-dal 中的确切含义，确保术语在不同上下文中的一致性。"
            }
        ]
    }
}
```

###### Query 改写(翻译)
需求agent拆解后的需求点一般是中文，不能直接用来召回。所以我们一般会用LLM将需求翻译成英文。具体过程是：
+ <u>识别核心任务。`“点击导出按钮后页面卡住，aone接口返回500，paramJson里divisionId为空”。“导出按钮”功能是主干，错误是表象`</u>
+ <u>基于项目词典库的翻译</u>：因为一个中文词汇翻译成英文会有多种翻译的方式，基于词典表，有二义的中文词语，尽量用词汇表的单词来表示
+ <u>翻译结果必须可执行：输出是进行召回的，所以要遵守代码命名习惯，构建一个简短的英文检索短语（动词+名词形式）</u>

```
你是一位资深的AI开发助手，专长是分析软件开发需求。你的任务是解析用户提供的需求或问题，并生成一个简洁、高层次、用于代码检索的核心英文关键词。

【核心目标】
从复杂的需求描述中，提炼出开发者为解决问题需首先定位的核心业务功能或代码模块。你的目标是找出最关键的开发切入点，而不是复述需求的全部细节。

【输入】
原始需求 (${originalIssueContent}): 用户提供的详细需求、功能描述或问题报告。
动态语料库 (${dynamic_corpus}): (可选) 一个项目相关的技术术语或业务词典，用于辅助你理解和翻译专有名称。

【处理规则】
识别核心任务: 首先，通读并理解 ${originalIssueContent} 的主要内容。判断整个需求是围绕哪个核心业务功能展开的，例如：“创建项目”、“用户登录”、“数据导出”等。这是最高优先级的分析任务。
提取关键实体: 识别需求中提到的具体技术名词，如变量名 (paramJson)、参数 (divisionId)、外部服务 (aone接口) 等。这些是理解问题场景的辅助信息，但不应主导最终的输出。
构建检索关键词:
以你识别出的 核心任务 为主干，构建一个简短的英文检索短语。
关键词应主要包含代表核心任务的动词和名词 (Verb + Noun)，例如 "Create Project", "Import Risk Data"。
避免 在关键词中堆砌细节、错误信息或排查过程的描述。关键词应当模拟一个资深开发者在IDE搜索框中输入的、用于快速定位功能入口的内容。
参考 ${dynamic_corpus} 来确保专业术语翻译的准确性。

【输出格式】
请以JSON数组格式返回结果，每个对象包含：{
  "originalIssueContent": "${originalIssueContent}",
  "query": "英文检索关键词"
}
```

##### 粗排(多路召回)
###### 中文召回
+ 将 中文需求embedding后 进行 中文注释 召回。取TOP50
    > 一般codebase的工具入参都是外层比较纯净的词语了。
    > 为什么中文注释和代码块取TOP50？<u>因为一个方法有多条注释，难免召回有重复的方法，多召回一些，后面会过滤。</u>
+ 将 中文需求 进行 中文关键词 and召回。取TOP10
    > 为什么用and逻辑（即文本内容分词后的term全匹配才召回）？<u>因为中文关键字来源于LLM整理的方法级别的高度概括，用户有很大可能性命中全部关键词的。另外为了解决高频词霸权，例如“如果是风险平台，那么很多方法都会出现“风险”关键字，用or就容易召回“提交风险”，“资金风险”，“查询风险项”等</u>
    > 为什么关键词取TOP10？<u>因为关键词是and逻辑，是比较准确的，可以少取一些。而且这10个召回的方法不重复的。</u>

###### 英文召回
+ 将 翻译后的英文需求embedding后 进行 代码块 召回。取TOP50
+ 将 翻译后的英文需求 进行 英文关键词 or召回。取TOP30
    > 为什么用or逻辑（即文本内容分词后的term匹配上一项就召回）？<u>因为英文关键字来源于方法签名(方法名，参数类型，参数名称等)，用户非常小概率会把这些关键词全都输入完整，用and就容易让 “英文关键词召回”失效。</u>
    > 为什么关键词取TOP30？<u>因为关键词是or逻辑，不太准确（有高频词霸权可能性），可以多取一些。</u>

##### 精排
目的：根据粗排阶段获取到的多路召回结果（大概130条），进行综合的排序（大概取10-20条）。
1. <u>对每一路召回进行一次聚类函数</u>findHighGroups（阈值取2。因为每一路召回太多了，我们指定了top50，其实可能就前10项就分数比较高，后40项分数较低，所以<u>这一步需要过滤掉明显的断层低分记录）</u>
2. <u>Rerank 算法，实现多方面的需求-代码相关性判断</u>
3. <u>多次聚类，逐步收紧筛选条件，确保只保留真正相关的高质量结果。</u>


###### 聚类函数findHighGroups
**效果：**
```
输入: [0.95, 0.92, 0.88, 0.72, 0.45, 0.42]
高分组: [0.95, 0.92, 0.88, 0.72]
低分组: [0.45, 0.42]
```

**核心：**
findHighGroups 是一个基于差值断层的自适应分组算法。
核心思想是：找到分数序列中的"断崖式下跌"点作为高低分界线。

```
输入: [0.72, 0.95, 0.45, 0.88, 0.92, 0.42]
Step 1: 降序排序
sorted = [0.95, 0.92, 0.88, 0.72, 0.45, 0.42]

Step 2: 计算相邻差值
diffs = [0.03, 0.04, 0.16, 0.27, 0.03]
          ↑     ↑     ↑     ↑     ↑
        0.95  0.92  0.88  0.72  0.45
         -     -     -     -     -
        0.92  0.88  0.72  0.45  0.42

Step 3: 计算相邻差值平均值，得到动态阈值
avgDiff = (0.03 + 0.04 + 0.16 + 0.27 + 0.03) / 5 = 0.106
threshold = avgDiff × 2 = 0.212 // 阈值 = 平均差值的2倍，用于识别"异常大的跳跃" 自适应：不同数据分布有不同的平均间距。2倍：统计学上，超过2倍标准差通常被认为是"异常值"

Step 4: 找分割点，第一个超过阈值的位置就是高低分界点
diffs = [0.03, 0.04, 0.16, 0.27, 0.03]
                            ↑
                     0.27 > 0.212 ✓ 找到断点！
                     splitIndex = 4

高分组 = sorted[0:4] = [0.95, 0.92, 0.88, 0.72]
```

###### Rerank 算法
**Rerank 算法：**
目标：将用户的需求跟召回阶段返回的候选代码块进行<u>重打分，希望识别出功能是否正确（代码块是否能够完成用户需求），以及候选的代码块是否是有质量的。
> 如果功能正确性好，候选的代码块质量也好，那肯定是高质量匹配。
> 如果功能全正确，但候选的代码块质量很差的（如命名都是`a,b,c`表达不清），所以要降低分。</u>


<u>原理总结：利用 F1 捕捉表层关键词覆盖，词向量余弦对齐动作意图，CodeBERT 建模深层逻辑语义，三者融合实现高精度的需求-代码相关性。</u>


所以将Prompt的打分过程划分为 `需求解析 → 代码解析 → 匹配度计算 →` 三个阶段。

+ 需求解析阶段：作用判断功能是否正确。
    + 先提取需求中的核心关键词：包括功能点（如“支持多门店独立核算”）、关键参数（如“门店id”）、逻辑约束（如“库存不足时禁止提交订单”）
    + 关注需求中的动词。用词向量<u>计算需求中的动词与方法签名的动词余弦相似度</u>，并取 Top3 的均值。
        > <u>作用1：用来缓解同义词带来的匹配断裂问题，比如`“生成”和 build()、create()` 都可能合理
        > 作用2：聚集动词而非核心业务实体词。降低关键词霸权</u>。比如召回里有 `“取消订单”,"提交订单","禁止提交订单"`，可以根据用户需求`“库存不足时禁止提交订单”` 聚焦于动作`禁止提交`，而非核心业务实体词`订单`
    + <u>深度语义匹配，引入 CodeBERT 语言模型，计算需求和代码的语义相似度。</u>
        > <u>作用: 用来能捕捉到`“库存不足时禁止提交订单”和 if (stock <= 0) throw new Exception()` 之间的深层语义关联</u>
    > 把动词余弦相似度（占 30%）和 语义相似度（占 70%）加权融合，得到 EM 分
    
+ 代码解析阶段：作用是候选的代码块是否是有质量的，检查代码的命名是否反映业务语义。
    + <u>提取代码块里的标识符（如 函数名、变量名</u>`*Service, *Dao, *DTO`）
    + <u>提取代码块里的标识符跟需求中提取的关键词做</u> TF-IDF 加权的 <u>F1 计算，得到F1分数。</u>
        > <u>TF-IDF 加权</u>：高频但无区分度的词（如`“处理”、“系统”`）权重低；低频但关键的业务词（如`“库存”、“门店ID”`）权重高
        > <u>F1 分数：衡量在需求中提取的核心关键词和代码之间重合的程度（既看查准率也看查全率）</u>

+ 匹配度计算阶段：把 EM 得分（占 70%）和标识符 F1（占 30%）加权融合，得到总分。
    > 系数分配是基于经验：我认为功能正确性远比命名规范更重要。功能正确性是底线要求（占 70%），而命名规范是可维护性信号（占 30%）。即使命名较差，只要逻辑正确仍可能可用；但若逻辑错误，命名再好也无意义
    

```
你是一个需求与代码匹配度评估专家，请根据以下规则对输入的需求和代码块进行评分，输出的结果只需要json返回。  
**输入参数**：  
- 需求内容（${issue_content}）: [用户提供的需求文本]  
- 代码块（${chunk_code}）: [用户提供的代码块]  

**评估步骤**：  
1. **需求解析**  
   - 1.提取需求中的核心功能点（如“支持多门店独立核算”）、关键参数（如“门店ID”）、逻辑约束（如“库存不足时禁止下单”）。  
   - 2.动词校验：需求动词与方法名动词的余弦相似度，取TOP3相似词匹配度均值作为动词得分（0-1）。  
   - 3.语义分析：使用BERT-code模型对需求文本和代码块进行联合编码，计算两者的语义相似度（取值范围0-1），该相似度作为代码逻辑与需求描述的整体匹配度。  

2. **代码解析**  
   - 提取代码中的函数名、变量名、API调用、逻辑分支（如`if (stock < 0)`）。  
   - 生成代码标识符集合（例如：`*Service`、`*Dao`、`*BO`、`*DTO`、`*VO`、`*check_stock()`、`*DO`、`*Facade`、`*Client`）。  

3. **匹配度计算**  
   - **精确匹配（EM）**：  
     EM = 0.7 * BERT_code_sim + 0.3 * 动词相似度均值  
     （若代码块中缺乏方法体，BERT_code_sim=0）  
   - **标识符F1**：  
     1. 精确率 = |需求关键词∩代码标识符| / |代码标识符|  
     2. 召回率 = |需求关键词∩代码标识符| / |需求关键词|  
     3. F1 = 2*(精确率*召回率)/(精确率+召回率)  
     （采用TF-IDF加权匹配，权重因子α=0.6）  

4. **综合评分**  
   \text{总分} = 0.7 \times \text{EM} + 0.3 \times \text{F1}

**输出格式**：  
返回结构化JSON，包含以下字段：  
- `code_identifiers`: 提取的代码标识符  
- `em_score`: 精确匹配得分（0-1）  
- `f1_score`: 标识符F1分数（0-1）  
- `final_score`: 综合评分（0-1）  
```

**为什么基于Prompt来做？**
Rerank 算法主要分为三大类：基于深度学习模型（交叉编码器）、基于大语言模型（LLM）以及经典 Learning to Rank 模型。
+ <u>基于深度学习模型：它将“查询（Query）”和“文档（Document）”拼接在一起作为一个整体输入模型</u>（例如 `[CLS] query [SEP] document [SEP]`）。<u>模型通过注意力机制捕捉两者之间细粒度的语义交互，从而输出一个相关性分数。精度高但速度慢。</u>如`BGE-Reranker`。
+ <u>基于大语言模型的 Rerank：</u>主要是通过设计特定的 Prompt来引导 LLM 进行排序。<u>具备极强的语义理解和零样本泛化能力，不需要专门的训练数据，且排序理由具有可解释性。</u>
+ <u>经典机器学习Learning to Rank (LTR) 模型：为“查询-文档”对提取大量特征</u>（如 BM25 得分、TF-IDF 值、文档长度、PageRank 等），<u>然后训练模型学习一个排序函数。</u>
+ <u>基于规则的排序融合算法：RRF（它不关心文档的具体内容或语义，只关心文档在各个检索源中的“位置”）效果很差。</u>


###### 多次聚类
**流程：**
该流程用于从原始分数列表中筛选出真正的“高分结果”，具体步骤如下：
1. <u>第一次聚类（findHighGroups）：对原始分数进行初步聚类，获得高分组。</u>
    + 如果高分组占总样本的比例 ≥ 50%，说明<u>低分样本过少，高分组样本留的太多了，需进行第二次聚类</u>（findHighGroups）以进一步过滤；
2. <u>在得到的高分组中，计算最高分与最低分的差值。
    + 如果分差 ≥ 0.22，说明高分内部差异较大，需进行第三次聚类以细化结果</u>
    + 如果分差 < 0.22，认为高分结果足够集中，直接返回最终高分组结果列表

```
原始分数列表
    ↓
第一次聚类 findHighGroups
    ↓
高分组 ≥ 50%? --Yes → 第二次聚类(说明低分分布太少，需要做一轮过滤)
    ↓ No
取边界值筛选高分
    ↓
高分结果中最高分和最低分的差值，分差 ≥ 0.22? -- Yes→ 第三次聚类
    ↓ No
返回最终高分组结果列表
```

##### 关键词过滤
✅ 1. 英文侧方法签名关键词提取时的显式过滤规则
“但要过滤以下内容：
jdk内置类型：如long、Map、String
框架类：如HttpServletRequest
特殊方法：如<init>、<clinit>”
“要过滤，规则是过滤掉 *DTO、通用框架(如Spring)、通用属性(如Name)、非核心操作动词(如set)”
✅ 这就是典型的关键词过滤：从方法名、参数、返回值中提取候选词后，主动剔除无业务区分度的通用词，只保留领域相关词汇。
✅ 2. 项目词典库构建过程中的语义过滤
“驼峰命名法拆分：createRiskBill → create, Risk, Bill
要过滤，规则如上
识别出领域名词和领域动词（英文和中文的解释）”
“领域名词词典 (Nouns)
Agent: 智能代理……
ChatClient: 聊天客户端……
✅ 这里通过 LLM + 规则，将原始拆分出的词汇进一步筛选，只把符合“领域概念”的词纳入词典。未被收录的词（如 util, handler, config）在后续检索中会被视为低价值词——这也是一种基于语义的关键词过滤。
✅ 3. 中文关键词召回使用 AND 逻辑（隐式过滤）
“为什么用and逻辑（即文本内容分词后的term全匹配才召回）？因为中文关键字来源于LLM整理的方法级别的概括，用户有很大可能性命中全部关键词……另外为了解决高频词霸权”
✅ 虽然没写“过滤”，但 AND 逻辑本质是一种查询时的动态过滤机制：只有同时包含所有关键词的文档才被召回，自动排除只含部分高频词（如仅含“风险”但不含“新增”）的噪声结果。
✅ 4. Rerank 阶段的 TF-IDF 加权（隐式降噪）
“TF-IDF 加权：高频但无区分度的词（如‘处理’、‘系统’）权重低；低频但关键的业务词（如‘库存’、‘门店ID’）权重高”
✅ 这是在打分阶段对关键词进行权重过滤：不是直接删除，而是让噪声词“说了也白说”，业务词“一票顶十票”。
🔍 总结
| 你的原文表述 | 对应的“关键词过滤”类型 |
|--------------|------------------------|
| “过滤掉 *DTO 、 set 、JDK 类型” | 显式黑名单过滤 |
| “识别出领域名词和动词” | 语义白名单过滤 |
| “AND 逻辑召回” | 查询时组合过滤 |
| “TF-IDF 降权通用词” | 打分时权重过滤 |

##### 代码扩写
根据精排召回的chunk，再取到完整的方法体， ~~相连的方法定义，~~ 以及类的成员变量 ~~，再删掉import。~~
作用：对模型来说是有完整语义的代码，减少回答幻觉的产生。

##### 效果
<u>召回`Recall@20 达90%`。精排显著提升排序区分度——将高度相似的粗排分数（如0.8），重排为层次分明的分数（如 0.2 / 0.5 / 0.9），精准识别与需求强相关的高质量代码片段。</u>

**数据集构建：**
| 是否成功 | 场景描述 | 召回策略 | 检索难点/失败案例 |
| :--- | :--- | :--- | :--- |
| **成功** | 需求强相关单个工具类 | 召回该工具类及其相关静态方法。 | 仅召回工具被调用它的业务类（除非需求明确要求）。 |
| **成功** | 需求强相关单个枚举 | 召回该枚举定义。 | 枚举值被硬编码在代码中，导致无法通过枚举名检索。 |
| **成功** | 需求强相关单个DAO层Mapper接口 | 召回该Mapper接口。 | 仅召回Mapper，不召回调用它的Service层（除非需求涉及业务逻辑）。 |
| **成功** | 需求强相关单个配置类或Bean | 召回该Bean定义。 | 难以区分是组件扫描的Bean还是@Bean方法定义的Bean。 |
| **成功** | 需求强相关 MVC 链路上的 Controller, Service, DAO | 召回整个调用链路。 | 链路过长，容易召回无关的中间层或切面，导致噪声过大。 |
| **成功** | 一个父类有两个子类，需求只跟父类 | 仅召回强相关的父类。 | 无法区分父类还是子类，导致召回了不相关的子类。 |
| **成功** | 一个父类有两个子类，需求只跟其中一个子类有关 | 仅召回强相关的子类。 | 无法区分多个子类，导致召回了不相关的子类。 |
| **失败** | 需求强相关关键词，代码里无关键词，关键词在数据库 | 通过数据库元数据或上下文推断。 | 关键词仅存在于数据库配置或外部资源中，代码中无直接文本匹配。 |
| **成功** | 某个方法被多个方法调用，但需求只跟一个调用方法强相关 | 仅召回强关联的调用方法。 | 方法被广泛复用，检索结果混杂了大量无关的调用点。 |
| **成功** | 模版类，具体实现在子类，需求强相关模版 | 仅召回模板类。 | 仅召回模板类，缺失具体的子类实现逻辑。 |
| **成功** | 模版类，具体实现在子类，需求强相关子类 | 仅召回具体子类。 | 仅召回模板类，缺失具体的子类实现逻辑。 |
| **部分失败** | try-catch块，需求强关联catch | 召回catch块 | catch信息不足，就打了一条简单日志 |
| **成功** | AOP切面，需求强相关Aspect切面类 | 召回AOP切面逻辑本身 | 难以理解切点表达式，导致无法准确召回对应的切面。 |
| **成功** | AOP切面，需求强相关被增强的目标方法 | 召回被AOP切入的目标方法。 | 无法通过AOP逻辑反向定位到具体的被切入方法。 |
| **成功** | 需求强相关if代码块 | 精确召回if分支内的代码。 | 召回了整个方法体，导致else分支或其他无关代码混入。 |

#### 代码编辑能力 edit_file+search_replace
**作用：**
<u>将模型输出的代码修改描述 真正应用生效到 真实的代码文件中。(apply 代码)</u>

**prompt：**
```
-- edit_file(AI处理): 要求带 ... existing code ...
使用此工具对现有文件提出编辑建议。该编辑将被一个较不智能的模型读取并快速应用。
您应清晰说明编辑内容，同时尽量减少未修改代码的书写。
在编写编辑时，应按顺序指定每项修改，并用特殊注释`// ... existing code ...`表示修改行之间的未变代码。例如：``` // ... existing code ... 第一次修改 // ... existing code ... 第二次修改 // ... existing code ... 第三次修改 // ... existing code ... ``` 建议尽量少重复原始文件中的代码行来传达变更。
但每项编辑应包含足够的上下文，即修改代码周围的未变代码，以消除歧义。
切勿省略原有代码段而未使用`// ... existing code ...`注释来表明其缺失。务必确保编辑内容明确。

-- search_replace(工程处理)：要求带 SEARCH/REPLACE块
请求使用SEARCH/replace块替换现有文件中的内容部分，这些块定义了对文件特定部分的确切更改。
遵循以下确切格式的一个或多个搜索/替换块：
<<<<<<< SEARCH
[exact content to find]
=======
[new content to replace with]
>>>>>>> REPLACE
关键规则：
1.搜索内容必须与关联的文件节匹配，才能准确找到：
 *匹配字符，包括空格、缩进、行尾
 *包括所有注释、文档字符串等。
2.搜索/替换块将仅替换第一个匹配项。
 *如果需要进行多次更改，请包含多个唯一的SEARCH/REPLACE块。
 *在每个搜索部分中包含*刚好*足够的行，以唯一匹配需要更改的每组行。
 *使用多个SEARCH/REPLACE块时，请按它们在文件中的显示顺序列出它们。
3.保持搜索/替换块简洁：
 *将大型搜索/替换块分解为一系列较小的块，每个块都会更改文件的一小部分。
 *只包括变化的线条，如果需要独特性，还可以包括一些周围的线条。
 *不要在SEARCH/REPLACE块中包含长时间不变的线条。
 *每一行都必须完整。切勿在中途截断线条，因为这可能会导致匹配失败。
4.特种作业：
 *要移动代码：使用两个SEARCH/REPLACE块（一个用于从原始位置删除，另一个用于插入新位置）
 *要删除代码：使用空的REPLACE部分
```

**入参：**
|       名称       |   类型   |                         描述                          |
| --------------- | ------- | ---------------------------------------------------- |
| targetFile           | String  | 要修改的目标文件                              |
| addFlag | String  | 文件是否新增, true:新增一个文件;false:修改已有文件 |
| instructions     | String  | 用一句话解释为什么使用这个工具，以及它如何有助于实现目标      |
| codeEdit | String  | edit_file工具参数，要修改的内容(existing code块)，即AI生成的代码   |
| diff | String  | search_replace工具参数，要修改的内容(SEARCH/replace块)，即AI生成的代码  |


**原理：**
+ <u>追求速度和准确率的结合，分层编辑策略：
    + 超过500行（一行60个token左右）的大文件，使用search_replace
    + 少于500行的小文件，使用edit_file；edit_file先用fast apply模型跑，跑出错了再用大模型跑，仍然出错回退到search_replace。</u>
+ 将这两个工具合二为一，入参也要包括existing code块和SEARCH/replace块

|          方式          |                     优点                     |                                 缺点                                 |               应用场景               |
| ---------------------- | ------------------------------------------- | -------------------------------------------------------------------- | ----------------------------------- |
| 大模型                  | 输出全文，准确率比较高                          | 速度慢（十几token/s）、token有3w左右上限、模型对数字不敏感（行替换会导致错误） | 500行以下的修改，再fast apply出错时代替 |
| fast apply(Qwen2.5)    | 输出全文，速度快(200token/s，1.5B标340token/s) | token有6w左右上限(标了26w)、模型对数字不敏感、准确率相较于大模型低           | 500行以下修改                         |
| SEARCH/replace块做diff | 准确率最高，但工程复杂（找到多条类似的语句）       | 依赖生成的内容                                                         | 500行以上的修改                       |

**数据：**
+ 13020个长度，220行。每行60个token，花费55s，每秒处理236个token
+ 353token长度，20行。每行20token，花费3.7s，每秒处理100token
+ 7791长度，185行。每行42token，花费34s，每秒处理230个token

所以：平均每行算40个token。LLM 1秒处理5行。平均200行大概要40s，小模型大概20s。

**search_replace问题1：**
<u>多段完全相同的代码片段时，执行替换时会遇到歧义。</u>
<u>解法1：扩大 SEARCH 范围，包含唯一上下文。提示词里加入 `在每个搜索部分中包含*刚好*足够的行，以唯一匹配需要更改的每组行。`</u>
<u>解法2：带一行文件行号。如`# FILE: auth.py L25-L27`</u>

**search_replace问题2：**
<u>LLM search块返回有一定概率空格或者格式不对。</u>

<u>解法：转正则表达式匹配，将空格部分全部换成 `.*`来正则搜索</u>
```
CodeGraphLogUtil.log("[updateFile] new content written to targetFile success. sessionId: " + sessionId, ", targetFile: " + targetFile.getAbsolutePath());
            } catch (BusinessException e) {
                throw e;
            } catch (IOException e) {
                throw new BusinessException("写入新内容时失败, targetFile: " + targetFile.getAbsolutePath() + ", e: " + e.getMessage());
            }
```
**search_replace问题3：**
<u>有时提供给大语言模型的是一小段代码片段。虽然该片段在上下文中语义明确、足以被准确识别，但在实际进行文件替换时却发现：在目标文件中，除了预期位置外，还存在另一处完全相同的代码片段。这可能导致替换操作影响到非预期的位置，引发错误或冗余修改。</u>
无解。

#### 代码编译能力 get_diagnostics_by_path
**作用：**
<u>在代码生成或修改操作后调用，以验证并修复语法或编译错误。</u>

**prompt：**
```
从项目中的特定文件检索诊断信息（错误、警告等）。
此工具应在任何代码生成或修改操作后调用，以验证和修复潜在问题。
需要一个filePathInProject参数，指定相对于项目根的目标文件路径。返回JSON格式的诊断列表，其中每个条目都包含：-path：找到诊断的文件路径-line：诊断的行号（从1开始）-严重性：严重性级别（“错误”、“警告”、“信息”或“提示”）-message：如果找不到诊断或文件不存在，诊断消息将返回空列表（[]）。
```

**入参：**
|       名称       |   类型   |                         描述                          |
| --------------- | ------- | ---------------------------------------------------- |
| filePathInProject           | String  | 编辑的文件相对地址                              |

**原理：**
+ <u>单文件级校验：javaparser框架的AST语法树来验证单文件编译是否通过。</u>
    > <u>不用 javac 命令，因为javac构建需要处理 jar依赖，lombok版本和jdk的版本兼容，外部依赖的类。</u>
    `
    /Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home/bin/javac -J--add-opens=jdk.compiler/com.sun.tools.javac=ALL-UNNAMED -proc:full -nowarn -Xlint:none -cp "/Users/chenzelei/Desktop/chenzeleitest/capd/ccc/:/Users/chenzelei/Desktop/chenzeleitest/capd/newclass/:capd-service/lib/*" -processorpath capd-service/lib/lombok-*.jar -sourcepath capd-service/src -d /Users/chenzelei/Desktop/chenzeleitest/capd/ccc/ capd-service/src/main/java/com/cainiao/capd/service/amdp/impl/DepartmentServiceImpl.java
    `
+ <u>整个项目级校验：采用maven来实现。</u>
    + <u>`maven-wrapper.jar`来通过终端命令行的方式来启动maven命令</u>
    + `maven-wrapper.properties`配置jar包的仓库
    + <u>pom.xml 里读到项目jdk版本。机器上安装了主流的8、11、17等版本启动对应命令进行编译</u>
    >`/Library/Java/JavaVirtualMachines/jdk1.8.0_291.jdk/Contents/Home/bin/java -DskipTests=true -Dmaven.test.skip=true -Dautoconfig.interactive=off  -classpath /Users/chenzelei/Desktop/chenzeleitest/risk-platform/.mvn/wrapper/maven-wrapper.jar -Dmaven.multiModuleProjectDirectory=/Users/chenzelei/Desktop/chenzeleitest/risk-platform/ org.apache.maven.wrapper.MavenWrapperMain -T 2 compile
`

**如何实时观察编译过程？**
1. <u>编译的过程流式输出到log日志文件里
2. 提交完编译任务时，会启动一个监听线程，监听log日志文件，每0.5s获取文件当前point指针，跟上一次的point指针比较
    + 如果`文件当前point指针>上一次的point指针`，可以读文件内容。如果读到`[DONE]`表示结束监听；如果读到内容则放到sink，sse返回前端
    + 如果`文件当前point指针==上一次的point指针`，所以当前没内容，则sse返回前端一个ping
3. 前端sse方式读取，并实时展示编译记录</u>



### 阻止模型生成坏代码
通过添加User Rules和Project Rules实现，可以在模型生成代码时就增加代码约束。由于这些规则会始终待在模型记忆中，所以不要写的非常长，可以在实践中逐渐补充内容。

**User Rules**
用户一次添加，多项目共享
```
除非非常必要，否则不要添加get和set，tostring，equals，hashcode等方法， 使用lombok注解替代
```

**Project Rules**
项目独属
```
### 特殊规则
1. 不使用@slf4j
2. 不使用@Autowired
3. 打印日志使用`private static final Logger log = Logger.getInstance(xxx.class)`
4. 使用`@Data`注解, 避免手写getter/setter方法，除非有特殊需求，否则不要手写toString和equals方法
5. 尽量不要生成太深的if else层级，可以将条件取反，提前结束等方式减少if else层级。
```

### 多轮会话
+ <u>产品设计上只支持两轮会话。根据需求会先产出一版代码修改，如果不满意，则输入修改意见进行第二版的LLM分析。每一次都是在上一版的基础上提出修改意见</u>
+ <u>因为LLM分析完后，最后一轮是总结所有的工作内容。所以我只需要把上一次的最后一轮消息拿出来，交给ai开启新一轮的迭代</u>
+ <u>没有指代问题，在产品设计上，对每一个修改的文件都可以提修改意见。 </u>比如`A文件逻辑哪里有错误，B文件无需改动`，不会出现`这个函数，上面那个类`

## Qoder
### 记忆
+ 对记忆进行总结并按关键字分类持久化形成死记忆
+ 检索会搜持久化的死记忆 + repo wiki + 代码召回
    > 建议：repo wiki更新会很慢，不能主动更新
### 多轮对话
+ 多轮对话里，第二次会先分析之前召回的代码，能回答问题就直接返回了。同样的问题新开的对话就要走检索逻辑。
    > 连续对话利用率 5-10分钟缓冲时间。理解不了

### Embedding
+ 推荐函数头包含注释，是不是把注释embedding了？
+ embedding召回时，会把前后的函数切断。总长度在60-100行左右。
    + 前面断的是for循环内的内容，不包含for那一行。
    + 后面断的 map字典的几列。
    + 感觉像是按固定token来写。
+ 检索会搜持久化的死记忆 + repo wiki + 代码召回

    
## 测评
### 测评技术方案
[SWE-bench](https://github.com/ZereChen/SWE-bench/blob/main/docs/README_CN.md)
[SWE-bench原理](https://zhuanlan.zhihu.com/p/1928490462039238458)
1. 抓取已经解决了问题开源PR
2. 对应的issue用LLM总结一下
3. issue 就是 query， PR就是召回的数据集。


### 客观测评
[测评文档](https://ata.atatech.org/articles/12020336916?spm=ata.23639746.0.0.38df6126QRLOA3#MDgxZGJi)
**数据生成逻辑**
+ 先找到代码作为正确答案，然后反向生成问题
+ 真实的需求里纯手工标记的数据

**采用指标**
+ 搜索阶段的结果是否准确
+ answer_any_match_rate 回答中引用了多少正确答案。`60%`

![](vx_images/843271713206.png =600x)


﻿﻿
### 端到端评测
**数据生成逻辑**
找到开源的仓库，根据Issue的问题，找到对应的git diff变更。构成300多条问答对。

**采用指标**
![](vx_images/226815952916521.png =600x)
﻿﻿

## AI未来发展
**AI Coding思维 从“辅助”到“自主智能体”**
AI 编程工具不再依赖用户的一问一答，而是能独立完成端到端的任务。
+ 最新的模型（如 Anthropic 11月底Claude Opus 4.5、OpenAI 12月 GPT-5.2-Codex），能接收一个模糊的需求，自主进行任务规划、使用终端工具、浏览代码库、编写代码、调试错误，甚至直接创建 Pull Request 完成交付。
+ 单次提示编程（One-shot）：以马斯克1月12预告的 Grok Code 升级为例，未来趋势是用户只需输入一次详细指令，AI 即可生成完整可用的复杂代码方案，无需多轮反复调试，极大提升效率。
+ qoder的 quest 模式。

**底层模型的比拼：**
1. 超长上下文与压缩技术
2025年12月 Qwen3-Coder 128K，2025年10月Kimi K2 256K。
上下文压缩：针对超长程的工程任务（如系统重构），GPT-5.2-Codex 能自动提炼历史对话和代码库的关键信息，丢弃冗余细节。
Qwen3-Max-Thinking：一是自适应工具调用能力，可按需调用搜索引擎和代码解释器，现已上线Qwen Chat。Qwen3-Max-Thinking能在对话中自主选择并调用其内置的搜索、记忆和代码解释器功能。这种能力让模型能像专业人士一样自主判断是否调用搜索、记忆或代码解释器，比如解答实时政策问题时自动检索最新信息，处理工程计算时启动代码工具验证结果，无需用户额外指令即可降低“幻觉”风险。



2. MoE架构（让模型在处理任务时，不需要激活全部参数，而是根据任务类型选择性地“唤醒”部分参数）
如 Qwen3-Coder引入Moe架构（480B 总参数，激活仅 35B），兼顾性能与推理成本。

3. deepseek一月份新出的两片论文
mHC 作用在残差连接，引入双随机矩阵解决在hc情况下的梯度消失，让训练更稳定。
Engram 作用在前馈全连接层，植入记忆能力释放计算力。

**产品功能创新**
1. 多模态输入 → 代码生成
局限于文本生成代码，GPT-5.2-Codex 和快手的 CodeFlicker 上传 Figma 设计图、手绘草图，AI 自动生成可运行前端代码。

2. Skill能力
把“脚本集合”进化成了一个高度模块化、具备独立运行环境的插件。支持渐进式prompt，工程上压缩上下文。
+ Slash Commands（斜杠命令） 合并进了 Skills 体系
+ Skills 可以在一个独立的子环境中运行

3. LSP（语言服务器协议）
Claude Code 等工具通过 LSP 精准理解代码结构，支持跳转定义、查找引用、调用链分析


**主流coding模型：**
| 模型名称                     | 所属机构 / 公司         | 开源 | 主要特点 |
|-----------------------------|------------------------|------|----------|
| **GPT-4 / GPT-4o / GPT-4o-mini** | OpenAI                 | ❌   | 多语言支持强，上下文理解优秀，GitHub Copilot 核心引擎，生态成熟 |
| **Claude 3.5 / Claude 4 / Claude Sonnet 4 / Claude 4.5** | Anthropic              | ❌   | 长上下文（最高 200K+），安全性高，复杂推理与工具调用能力强 |
| **Gemini 2.0 / Gemini Pro 2 / Gemini Experimental** | Google                 | ❌   | 原生多模态支持，深度集成于 Project IDX 和 Google Cloud Duet AI；代码生成质量高，尤其擅长 Python、Go、Java；支持实时协作与调试 |
| **CodeLlama / CodeLlama-Python / CodeLlama-Instruct** | Meta                   | ✅   | 基于 Llama 架构，代码补全与理解表现优异，适合本地部署 |
| **StarCoder2 / StarCoderBase** | Hugging Face + ServiceNow | ✅   | 训练数据来自 The Stack，多语言支持，适合研究与企业定制 |
| **DeepSeek-Coder (V1–V3)**   | DeepSeek（深度求索）     | ✅（部分） | 支持全栈开发、调试、测试生成，迭代快，中英文均衡 |
| **GLM-4.6**                  | 智谱 AI（Zhipu AI）      | ❌（商用）<br>✅（部分开源版） | 国产最强，200K 上下文，实测性能对标 Claude 4.5/GPT-5，低 token 消耗，适配国产芯片 |
| **Qwen3 / Qwen-Coder**       | 阿里通义实验室           | ✅（基础版）<br>❌（增强版） | 多语言支持，集成于通义灵码，IDE 插件完善，企业部署成熟 |
| **Kimi K2-Thinking**         | 月之暗面（Moonshot）     | ❌   | 强调智能体（Agent）能力，擅长任务规划与工具链协同 |
| **Doubao-Seed-Code**         | 字节跳动                | ❌   | 集成于火山引擎 Coding Plan，支持多模型自由切换，性价比高 |
| **HunYuan-Coder**            | 腾讯                    | ❌   | 与微信/腾讯云深度整合，适合企业内部开发流程 |
| **ERNIE Bot-Coding（文心一言）** | 百度                    | ❌   | ToB 布局早，管理功能强，支持私有化部署 |
| **Baichuan Coder 系列**      | 百川智能                | ✅（部分） | 开源+商用结合，适合中小团队定制开发 |
| **星熵（XingShen）**         | 美团                    | ✅   | 新兴免费模型，侧重工程落地与成本控制 |

